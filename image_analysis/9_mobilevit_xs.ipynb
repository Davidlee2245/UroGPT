{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76074960-e740-4203-bbdd-85d3df8be189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# 데이터셋에서 11개 패드에 각각 백본 + 공유엑스퍼트\n",
    "# fastvit_t8 (모델 내에 어텐션 없음)\n",
    "#\n",
    "# =============================================================================\n",
    "# 환경 설정 & 라이브러리 임포트\n",
    "# =============================================================================\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# GPU 설정\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"  # 사용할 GPU 지정\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"GPU 메모리 정리\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33e7612-20ce-46cf-815f-15b755c402a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [신규 셀] 라벨 매핑 규칙(MAIN_TO_AUX_MAP)이 성공적으로 생성되었습니다.\n",
      "  - 예시 (Ctrl): ('Hemo_Negative', 'Bilirubin_Negative', 'Protein_Negative', 'Nitrite_Negative', 'Glucose_Negative', 'IGNORE')\n",
      "  - 예시 (Protein_300): ('Hemo_Negative', 'Bilirubin_Negative', 'Protein_300', 'Nitrite_Negative', 'Glucose_Negative', 'IGNORE')\n",
      "  - 예시 (pH_5): ('Hemo_Negative', 'Bilirubin_Negative', 'Protein_Negative', 'Nitrite_Negative', 'Glucose_Negative', 'pH_5')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 벨 매핑 규칙 정의 (Multi-Task Learning 용)\n",
    "# =============================================================================\n",
    "#\n",
    "# 33개의 메인 클래스 정의\n",
    "MAIN_CLASSES = sorted(['Bilirubin_1',\n",
    " 'Nonhemo_250',\n",
    " 'Nonhemo_10',\n",
    " 'Glucose_2000',\n",
    " 'Nonhemo_50',\n",
    " 'Glucose_1000',\n",
    " 'Ctrl',\n",
    " 'Glucose_350',\n",
    " 'pH_9',\n",
    " 'Glucose_250',\n",
    " 'Bilirubin_3',\n",
    " 'Protein_10',\n",
    " 'pH_6.5',\n",
    " 'Glucose_100',\n",
    " 'pH_8',\n",
    " 'pH_6',\n",
    " 'Glucose_500',\n",
    " 'Nitrite_1',\n",
    " 'Protein_1000',\n",
    " 'Protein_30',\n",
    " 'Hemo_250',\n",
    " 'Protein_300',\n",
    " 'pH_5',\n",
    " 'Nitrite_0.5',\n",
    " 'pH_7',\n",
    " 'Glucose_1500',\n",
    " 'Hemo_10',\n",
    " 'Glucose_150',\n",
    " 'Bilirubin_0.5',\n",
    " 'Glucose_750',\n",
    " 'Protein_100',\n",
    " 'pH_7.5',\n",
    " 'Hemo_50'])\n",
    "\n",
    "#  6개 그룹별 클래스ㅅ\n",
    "#    - 0번 인덱스는 항상 음성 클래스로 고정 (pH 제외)\n",
    "AUX_CLASSES_GROUPS = {\n",
    "    # 0번 패드: Hemo/NonHemo (총 7개 클래스)\n",
    "    'aux_0': sorted(['Hemo_Negative', 'Hemo_10', 'Hemo_50', 'Hemo_250', 'Nonhemo_10', 'Nonhemo_50', 'Nonhemo_250']),\n",
    "    \n",
    "    # 1번 패드: Bilirubin (총 4개 클래스)\n",
    "    'aux_1': sorted(['Bilirubin_Negative', 'Bilirubin_0.5', 'Bilirubin_1', 'Bilirubin_3']),\n",
    "    \n",
    "    # 4번 패드: Protein (총 6개 클래스)\n",
    "    'aux_4': sorted(['Protein_Negative', 'Protein_10', 'Protein_30', 'Protein_100', 'Protein_300', 'Protein_1000']),\n",
    "    \n",
    "    # 5번 패드: Nitrite (총 3개 클래스)\n",
    "    'aux_5': sorted(['Nitrite_Negative', 'Nitrite_0.5', 'Nitrite_1']),\n",
    "    \n",
    "    # 6번 패드: Glucose (총 10개 클래스)\n",
    "    'aux_6': sorted(['Glucose_Negative', 'Glucose_100', 'Glucose_150', 'Glucose_250', 'Glucose_350', 'Glucose_500', 'Glucose_750', 'Glucose_1000', 'Glucose_1500', 'Glucose_2000']),\n",
    "    \n",
    "    # 7번 패드: pH (총 7개 클래스, 'Negative' 없음, 'IGNORE'(-1) 신호 사용)\n",
    "    'aux_7': sorted(['pH_5', 'pH_6', 'pH_6.5', 'pH_7', 'pH_7.5', 'pH_8', 'pH_9'])\n",
    "}\n",
    "\n",
    "# \"메인 라벨 -> 6개 보조 라벨\" 번역 규칙 딕셔너리\n",
    "# - 'IGNORE'는 Loss 계산에서 제외\n",
    "MAIN_TO_AUX_MAP = {}\n",
    "\n",
    "# 기본 '음성' 상태 정의\n",
    "DEFAULT_NEGATIVE_LABELS = {\n",
    "    'aux_0': 'Hemo_Negative',\n",
    "    'aux_1': 'Bilirubin_Negative',\n",
    "    'aux_4': 'Protein_Negative',\n",
    "    'aux_5': 'Nitrite_Negative',\n",
    "    'aux_6': 'Glucose_Negative',\n",
    "    'aux_7': 'IGNORE'  # pH는 'Negative'가 없고 'IGNORE' 처리\n",
    "}\n",
    "\n",
    "# 33개 메인 클래스에 대해\n",
    "for main_label_name in MAIN_CLASSES:\n",
    "    # 모든 보조 라벨을 기본 '음성' 상태로 초기화\n",
    "    aux_labels = DEFAULT_NEGATIVE_LABELS.copy()\n",
    "    \n",
    "    if main_label_name == 'Ctrl':\n",
    "        # 'Ctrl'은 모든 보조 라벨이 '음성'이므로, 'aux_labels'를 그대로 사용\n",
    "        pass\n",
    "        \n",
    "    # 2. '양성' 클래스인 경우, 해당하는 보조 라벨만 덮어쓰기\n",
    "    elif main_label_name.startswith('Hemo_') or main_label_name.startswith('Nonhemo_'):\n",
    "        aux_labels['aux_0'] = main_label_name\n",
    "        \n",
    "    elif main_label_name.startswith('Bilirubin_'):\n",
    "        aux_labels['aux_1'] = main_label_name\n",
    "        \n",
    "    elif main_label_name.startswith('Protein_'):\n",
    "        aux_labels['aux_4'] = main_label_name\n",
    "        \n",
    "    elif main_label_name.startswith('Nitrite_'):\n",
    "        aux_labels['aux_5'] = main_label_name\n",
    "        \n",
    "    elif main_label_name.startswith('Glucose_'):\n",
    "        aux_labels['aux_6'] = main_label_name\n",
    "        \n",
    "    elif main_label_name.startswith('pH_'):\n",
    "        aux_labels['aux_7'] = main_label_name # 'IGNORE' 대신 실제 pH 값으로 덮어쓰기\n",
    "    \n",
    "    # 완성된 6개 보조 라벨 튜플을 맵에 저장\n",
    "    MAIN_TO_AUX_MAP[main_label_name] = (\n",
    "        aux_labels['aux_0'],\n",
    "        aux_labels['aux_1'],\n",
    "        aux_labels['aux_4'],\n",
    "        aux_labels['aux_5'],\n",
    "        aux_labels['aux_6'],\n",
    "        aux_labels['aux_7']\n",
    "    )\n",
    "\n",
    "# 4. 보조 라벨 이름(str)을 인덱스(int)로 변환하는 헬퍼 딕셔너리 생성\n",
    "#    - 'IGNORE'는 -1로 매핑\n",
    "AUX_NAME_TO_INDEX_MAP = {\n",
    "    group_name: {name: i for i, name in enumerate(names)}\n",
    "    for group_name, names in AUX_CLASSES_GROUPS.items()\n",
    "}\n",
    "# 'IGNORE' 신호(-1) 추가\n",
    "for group_name in AUX_NAME_TO_INDEX_MAP:\n",
    "    AUX_NAME_TO_INDEX_MAP[group_name]['IGNORE'] = -1\n",
    "\n",
    "print(\"✅ [신규 셀] 라벨 매핑 규칙(MAIN_TO_AUX_MAP)이 성공적으로 생성되었습니다.\")\n",
    "print(f\"  - 예시 (Ctrl): {MAIN_TO_AUX_MAP['Ctrl']}\")\n",
    "print(f\"  - 예시 (Protein_300): {MAIN_TO_AUX_MAP['Protein_300']}\")\n",
    "print(f\"  - 예시 (pH_5): {MAIN_TO_AUX_MAP['pH_5']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6750c26d-4019-41c1-80f3-459202049cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HDF5UrinKitDataset\n",
    "# =============================================================================\n",
    "\n",
    "class HDF5UrinKitDataset(Dataset):\n",
    "    \"\"\"\n",
    "    HDF5 파일에서 센서 세트 데이터를 로드 (Multi-Task Learning 지원)\n",
    "    \"\"\"\n",
    "    def __init__(self, h5_path):\n",
    "        self.h5_path = h5_path\n",
    "        \n",
    "        # 라벨 매핑 규칙이 정의되어 있는지 확인 (앞의 [신규 셀] 실행 필수)\n",
    "        if 'MAIN_CLASSES' not in globals() or 'MAIN_TO_AUX_MAP' not in globals():\n",
    "            raise RuntimeError(\"라벨 매핑 규칙(MAIN_CLASSES 등)이 정의되지 않았습니다. [신규 셀]을 먼저 실행하세요.\")\n",
    "\n",
    "        with h5py.File(h5_path, 'r') as f:\n",
    "            self.length = len([k for k in f.keys() if k.startswith('sensor')])\n",
    "            \n",
    "        print(f\"HDF5 데이터 준비 완료: {self.length}개 센서 세트 (MTL 모드)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        필요할 때만 데이터 로드\n",
    "        Returns:\n",
    "            tuple: (\n",
    "                sensor_set (torch.Tensor): (11, 3, 224, 224) 이미지 세트\n",
    "                main_label (torch.Tensor): (1,) 메인 라벨 (예: 'Protein_300'의 인덱스)\n",
    "                aux_labels (torch.Tensor): (6,) 보조 라벨 6개의 인덱스 텐서\n",
    "            )\n",
    "        \"\"\"\n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            sensor_set = torch.from_numpy(f[f'sensor_{idx}'][:])\n",
    "            \n",
    "            # 1. 메인 라벨(스칼라) 로드\n",
    "            label_data = f[f'label_{idx}']\n",
    "            if label_data.shape == ():  # 스칼라인 경우\n",
    "                main_label_idx = torch.tensor(label_data[()])\n",
    "            else:  # 배열인 경우\n",
    "                main_label_idx = torch.from_numpy(label_data[:]).squeeze()\n",
    "        \n",
    "        # 2. [신규] 메인 라벨을 6개 보조 라벨로 \"번역\"\n",
    "        try:\n",
    "            # 메인 라벨 인덱스 -> 메인 라벨 이름 (예: 25 -> 'Protein_300')\n",
    "            main_label_name = MAIN_CLASSES[main_label_idx.item()]\n",
    "            \n",
    "            # 메인 라벨 이름 -> 6개 보조 라벨 이름 (예: ('Hemo_Negative', ..., 'Protein_300', ..., 'IGNORE'))\n",
    "            aux_label_names = MAIN_TO_AUX_MAP[main_label_name]\n",
    "            \n",
    "            # 6개 보조 라벨 이름 -> 6개 보조 라벨 인덱스 (예: (0, 0, 4, 0, 0, -1))\n",
    "            aux_label_indices = [\n",
    "                AUX_NAME_TO_INDEX_MAP['aux_0'][aux_label_names[0]], # Hemo\n",
    "                AUX_NAME_TO_INDEX_MAP['aux_1'][aux_label_names[1]], # Bili\n",
    "                AUX_NAME_TO_INDEX_MAP['aux_4'][aux_label_names[2]], # Protein\n",
    "                AUX_NAME_TO_INDEX_MAP['aux_5'][aux_label_names[3]], # Nitrite\n",
    "                AUX_NAME_TO_INDEX_MAP['aux_6'][aux_label_names[4]], # Glucose\n",
    "                AUX_NAME_TO_INDEX_MAP['aux_7'][aux_label_names[5]]  # pH\n",
    "            ]\n",
    "            \n",
    "            aux_labels_tensor = torch.tensor(aux_label_indices, dtype=torch.long)\n",
    "            \n",
    "        except IndexError:\n",
    "            print(f\"치명적 오류: HDF5의 메인 라벨 인덱스 {main_label_idx.item()}가 MAIN_CLASSES (총 {len(MAIN_CLASSES)}개) 범위를 벗어납니다.\")\n",
    "            raise\n",
    "        except KeyError:\n",
    "            print(f\"치명적 오류: 메인 라벨 {main_label_name}을(를) MAIN_TO_AUX_MAP에서 찾을 수 없습니다.\")\n",
    "            raise\n",
    "\n",
    "        return sensor_set, main_label_idx, aux_labels_tensor\n",
    "\n",
    "# --- Pickle to HDF5 변환 함수 ---\n",
    "def convert_pickle_to_hdf5(pickle_path, h5_path):\n",
    "    \"\"\"Pickle 파일을 HDF5로 변환\"\"\"\n",
    "    print(f\"변환 시작: {pickle_path} → {h5_path}\")\n",
    "    \n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    with h5py.File(h5_path, 'w') as f:\n",
    "        for i, (sensor_set, label) in enumerate(tqdm(data, desc=\"HDF5 변환\")):\n",
    "            f.create_dataset(f'sensor_{i}', data=sensor_set.numpy(), compression='gzip')\n",
    "            # 라벨을 스칼라로 저장\n",
    "            if hasattr(label, 'item'):\n",
    "                f.create_dataset(f'label_{i}', data=label.item())\n",
    "            else:\n",
    "                f.create_dataset(f'label_{i}', data=label)\n",
    "    \n",
    "    print(f\"변환 완료: {len(data)}개 샘플\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984ef09e-4c1b-4e32-9f5a-fa13f84e06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [수정된 셀 3] NaturePaperStyleDataset\n",
    "# - __getitem__이 3개 값(sensor_set, main_label, aux_labels)을\n",
    "#   올바르게 처리하도록 수정\n",
    "# =============================================================================\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from torchvision import transforms as T\n",
    "import cv2\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "# (NaturePaperAugmentation, ProfessionalDataAugmentation, AddressEnvironmentalAugmentation\n",
    "#  클래스들은 기존과 동일 - 수정 없음)\n",
    "\n",
    "class NaturePaperAugmentation:\n",
    "    \"\"\"Nature Communications 논문 스타일의 체계적 데이터 증강\"\"\"\n",
    "    \n",
    "    def __init__(self, augmentation_level: str = \"all_surroundings\"):\n",
    "        self.augmentation_level = augmentation_level\n",
    "        self.setup_augmentation_parameters()\n",
    "    \n",
    "    def setup_augmentation_parameters(self):\n",
    "        \"\"\"논문 기반 증강 파라미터 설정\"\"\"\n",
    "        if self.augmentation_level == \"single_light\":\n",
    "            self.brightness_range = (0.8, 1.2)\n",
    "            self.contrast_range = (0.8, 1.2)\n",
    "            self.color_temp_range = (0.9, 1.1)\n",
    "            self.blur_sigma_range = (0.1, 0.5)\n",
    "            self.crop_scale_range = (0.9, 1.0)\n",
    "        elif self.augmentation_level == \"multi_light\":\n",
    "            self.brightness_range = (0.6, 1.4)\n",
    "            self.contrast_range = (0.7, 1.3)\n",
    "            self.color_temp_range = (0.85, 1.15)\n",
    "            self.blur_sigma_range = (0.1, 0.8)\n",
    "            self.crop_scale_range = (0.85, 1.0)\n",
    "        else:  # \"all_surroundings\"\n",
    "            self.brightness_range = (0.4, 1.6)\n",
    "            self.contrast_range = (0.5, 1.5)\n",
    "            self.color_temp_range = (0.8, 1.2)\n",
    "            self.blur_sigma_range = (0.1, 1.2)\n",
    "            self.crop_scale_range = (0.8, 1.0)\n",
    "\n",
    "class ProfessionalDataAugmentation:\n",
    "    \"\"\"논문 수준의 전문적 데이터 증강 시스템\"\"\"\n",
    "    \n",
    "    def __init__(self, config: NaturePaperAugmentation):\n",
    "        self.config = config\n",
    "        \n",
    "    def apply_color_temperature_modulation(self, image: Image.Image, intensity: float = None) -> Image.Image:\n",
    "        \"\"\"색온도 변조 - 스마트폰별 색상 차이 대응\"\"\"\n",
    "        if intensity is None:\n",
    "            intensity = random.uniform(*self.config.color_temp_range)\n",
    "        \n",
    "        r, g, b = image.split()\n",
    "        \n",
    "        if intensity > 1.0:\n",
    "            r_factor = intensity\n",
    "            b_factor = 1.0 / intensity\n",
    "            g_factor = 1.0\n",
    "        else:\n",
    "            r_factor = intensity\n",
    "            b_factor = 1.0 / intensity  \n",
    "            g_factor = 1.0\n",
    "        \n",
    "        r = ImageEnhance.Brightness(r).enhance(r_factor)\n",
    "        b = ImageEnhance.Brightness(b).enhance(b_factor)\n",
    "        g = ImageEnhance.Brightness(g).enhance(g_factor)\n",
    "        \n",
    "        return Image.merge('RGB', (r, g, b))\n",
    "    \n",
    "    def apply_contrast_modulation(self, image: Image.Image, intensity: float = None) -> Image.Image:\n",
    "        \"\"\"대비 변조 - 카메라 센서 품질 차이 대응\"\"\"\n",
    "        if intensity is None:\n",
    "            intensity = random.uniform(*self.config.contrast_range)\n",
    "        \n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        return enhancer.enhance(intensity)\n",
    "    \n",
    "    def apply_brightness_modulation(self, image: Image.Image, intensity: float = None) -> Image.Image:\n",
    "        \"\"\"밝기 변조 - 조명 환경 변화 대응\"\"\"\n",
    "        if intensity is None:\n",
    "            intensity = random.uniform(*self.config.brightness_range)\n",
    "        \n",
    "        enhancer = ImageEnhance.Brightness(image)\n",
    "        return enhancer.enhance(intensity)\n",
    "    \n",
    "    def apply_gaussian_blur(self, image: Image.Image, sigma: float = None) -> Image.Image:\n",
    "        \"\"\"가우시안 블러 - 촬영 시 초점 문제 대응\"\"\"\n",
    "        if sigma is None:\n",
    "            sigma = random.uniform(*self.config.blur_sigma_range)\n",
    "        \n",
    "        return image.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "    \n",
    "    def apply_horizontal_flip(self, image: Image.Image, probability: float = 0.5) -> Image.Image:\n",
    "        \"\"\"수평 뒤집기 - 촬영 각도 변화 대응\"\"\"\n",
    "        if random.random() < probability:\n",
    "            return image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        return image\n",
    "    \n",
    "    def apply_stochastic_crop_resize(self, image: Image.Image, scale_range: Tuple[float, float] = None) -> Image.Image:\n",
    "        \"\"\"확률적 크롭 및 리사이징 - 거리/위치 변화 대응\"\"\"\n",
    "        if scale_range is None:\n",
    "            scale_range = self.config.crop_scale_range\n",
    "        \n",
    "        scale = random.uniform(*scale_range)\n",
    "        width, height = image.size\n",
    "        \n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        \n",
    "        left = random.randint(0, width - new_width)\n",
    "        top = random.randint(0, height - new_height)\n",
    "        \n",
    "        cropped = image.crop((left, top, left + new_width, top + new_height))\n",
    "        return cropped.resize((width, height), Image.LANCZOS)\n",
    "\n",
    "class AdvancedEnvironmentalAugmentation:\n",
    "    \"\"\"고급 환경적 증강\"\"\"\n",
    "    \n",
    "    def apply_lighting_condition_simulation(self, image: Image.Image) -> Image.Image:\n",
    "        \"\"\"조명 조건 시뮬레이션\"\"\"\n",
    "        lighting_scenarios = [\n",
    "            (\"dim_indoor\", 0.3, 0.8),\n",
    "            (\"office_fluorescent\", 0.9, 1.1),\n",
    "            (\"bright_outdoor\", 1.3, 1.5),\n",
    "            (\"hospital_led\", 1.1, 1.2),\n",
    "            (\"car_interior\", 0.4, 0.7),\n",
    "        ]\n",
    "        \n",
    "        scenario_name, min_bright, max_bright = random.choice(lighting_scenarios)\n",
    "        brightness = random.uniform(min_bright, max_bright)\n",
    "        \n",
    "        return ImageEnhance.Brightness(image).enhance(brightness)\n",
    "    \n",
    "    def apply_shadow_and_glare_effects(self, image: Image.Image) -> Image.Image:\n",
    "        \"\"\"그림자 및 반사광 효과\"\"\"\n",
    "        effect_type = random.choice([\"shadow\", \"glare\", \"none\"])\n",
    "        \n",
    "        if effect_type == \"shadow\":\n",
    "            img_array = np.array(image)\n",
    "            h, w = img_array.shape[:2]\n",
    "            shadow_x = random.randint(0, w//2)\n",
    "            shadow_y = random.randint(0, h//2)\n",
    "            shadow_w = random.randint(w//4, w//2)\n",
    "            shadow_h = random.randint(h//4, h//2)\n",
    "            \n",
    "            shadow_intensity = random.uniform(0.6, 0.9)\n",
    "            img_array[shadow_y:shadow_y+shadow_h, shadow_x:shadow_x+shadow_w] = \\\n",
    "                (img_array[shadow_y:shadow_y+shadow_h, shadow_x:shadow_x+shadow_w] * shadow_intensity).astype(np.uint8)\n",
    "            \n",
    "            return Image.fromarray(img_array)\n",
    "            \n",
    "        elif effect_type == \"glare\":\n",
    "            img_array = np.array(image)\n",
    "            h, w = img_array.shape[:2]\n",
    "            glare_x = random.randint(0, w//2) \n",
    "            glare_y = random.randint(0, h//2)\n",
    "            glare_w = random.randint(w//6, w//3)\n",
    "            glare_h = random.randint(h//6, h//3)\n",
    "            \n",
    "            glare_intensity = random.uniform(1.2, 1.4)\n",
    "            img_array[glare_y:glare_y+glare_h, glare_x:glare_x+glare_w] = \\\n",
    "                np.clip(img_array[glare_y:glare_y+glare_h, glare_x:glare_x+glare_w] * glare_intensity, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            return Image.fromarray(img_array)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# =============================================================================\n",
    "# [수정됨] NaturePaperStyleDataset\n",
    "# =============================================================================\n",
    "class NaturePaperStyleDataset:\n",
    "    \"\"\"Nature 논문 스타일의 체계적 데이터셋 클래스 (MTL 지원)\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dataset, augmentation_level: str = \"all_surroundings\", \n",
    "                 augmentation_factor: int = 10):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.augmentation_factor = augmentation_factor\n",
    "        \n",
    "        self.config = NaturePaperAugmentation(augmentation_level)\n",
    "        self.basic_aug = ProfessionalDataAugmentation(self.config)\n",
    "        self.advanced_aug = AdvancedEnvironmentalAugmentation()\n",
    "        \n",
    "        self.augmentation_combinations = self._define_augmentation_combinations()\n",
    "        \n",
    "    def _define_augmentation_combinations(self) -> List[Dict]:\n",
    "        \"\"\"논문에서 사용된 다양한 증강 조합 정의\"\"\"\n",
    "        # (이 함수는 수정 없음, 기존과 동일)\n",
    "        combinations = [\n",
    "            {\"name\": \"original\", \"transforms\": []},\n",
    "            {\"name\": \"brightness_only\", \"transforms\": [\"brightness\"]},\n",
    "            {\"name\": \"contrast_only\", \"transforms\": [\"contrast\"]}, \n",
    "            {\"name\": \"color_temp_only\", \"transforms\": [\"color_temperature\"]},\n",
    "            {\"name\": \"blur_only\", \"transforms\": [\"gaussian_blur\"]},\n",
    "            {\"name\": \"flip_only\", \"transforms\": [\"horizontal_flip\"]},\n",
    "            {\"name\": \"crop_only\", \"transforms\": [\"stochastic_crop\"]},\n",
    "            {\"name\": \"brightness_contrast\", \"transforms\": [\"brightness\", \"contrast\"]},\n",
    "            {\"name\": \"brightness_blur\", \"transforms\": [\"brightness\", \"gaussian_blur\"]},\n",
    "            {\"name\": \"contrast_flip\", \"transforms\": [\"contrast\", \"horizontal_flip\"]},\n",
    "            {\"name\": \"color_temp_crop\", \"transforms\": [\"color_temperature\", \"stochastic_crop\"]},\n",
    "            {\"name\": \"lighting_combo\", \"transforms\": [\"brightness\", \"contrast\", \"color_temperature\"]},\n",
    "            {\"name\": \"distortion_combo\", \"transforms\": [\"gaussian_blur\", \"horizontal_flip\", \"stochastic_crop\"]},\n",
    "            {\"name\": \"indoor_office\", \"transforms\": [\"brightness\", \"contrast\", \"lighting_condition\"]},\n",
    "            {\"name\": \"outdoor_bright\", \"transforms\": [\"brightness\", \"color_temperature\", \"shadow_glare\"]},\n",
    "            {\"name\": \"low_light\", \"transforms\": [\"brightness\", \"gaussian_blur\"]},\n",
    "            {\"name\": \"full_augmentation\", \"transforms\": [\"brightness\", \"contrast\", \"color_temperature\", \n",
    "                                                       \"gaussian_blur\", \"horizontal_flip\", \"stochastic_crop\",\n",
    "                                                       \"lighting_condition\", \"shadow_glare\"]},\n",
    "        ]\n",
    "        \n",
    "        if self.config.augmentation_level == \"single_light\":\n",
    "            return [c for c in combinations if len(c[\"transforms\"]) <= 2]\n",
    "        elif self.config.augmentation_level == \"multi_light\":\n",
    "            return [c for c in combinations if len(c[\"transforms\"]) <= 4 and \"lighting_condition\" not in c[\"transforms\"]]\n",
    "        else:\n",
    "            return combinations\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset) * self.augmentation_factor\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        [수정됨] 3개 값(sensor_set, main_label, aux_labels)을 반환하도록 수정\n",
    "        \"\"\"\n",
    "        original_idx = idx % len(self.base_dataset)\n",
    "        augmentation_idx = idx // len(self.base_dataset)\n",
    "        \n",
    "        # 1. [수정] HDF5(base_dataset)로부터 3개의 항목을 로드\n",
    "        sensor_set, main_label, aux_labels = self.base_dataset[original_idx]\n",
    "        \n",
    "        # 2. 증강 팩터가 1이면(augmentation_idx가 0), 로드한 원본 3개 항목 반환\n",
    "        if self.augmentation_factor == 1:\n",
    "            return sensor_set, main_label, aux_labels\n",
    "\n",
    "        # 3. 팩터가 1보다 클 때도, 첫 번째(idx=0)는 원본 3개 항목 반환\n",
    "        if augmentation_idx == 0:\n",
    "            return sensor_set, main_label, aux_labels\n",
    "        \n",
    "        # --- 4. 이하 증강 로직 수행 ---\n",
    "        # (sensor_set, main_label, aux_labels는 이미 로드되어 있음)\n",
    "        \n",
    "        combination = random.choice(self.augmentation_combinations)\n",
    "        \n",
    "        augmented_patches = []\n",
    "        for sensor_idx in range(11):\n",
    "            sensor_patch = sensor_set[sensor_idx]\n",
    "            sensor_np = (sensor_patch.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "            sensor_pil = Image.fromarray(sensor_np)\n",
    "            \n",
    "            augmented_image = self._apply_augmentation_combination(sensor_pil, combination[\"transforms\"])\n",
    "            \n",
    "            augmented_tensor = T.ToTensor()(augmented_image)\n",
    "            augmented_patches.append(augmented_tensor)\n",
    "        \n",
    "        augmented_sensor_set = torch.stack(augmented_patches)\n",
    "        \n",
    "        # 5. [수정] 증강된 이미지(augmented_sensor_set)와,\n",
    "        #    원본 라벨 2개(main_label, aux_labels)를 반환\n",
    "        return augmented_sensor_set, main_label, aux_labels\n",
    "    \n",
    "    def _apply_augmentation_combination(self, image: Image.Image, transform_names: List[str]) -> Image.Image:\n",
    "        \"\"\"선택된 증강 조합을 순차적으로 적용 (수정 없음, 기존과 동일)\"\"\"\n",
    "        for transform_name in transform_names:\n",
    "            if transform_name == \"brightness\":\n",
    "                image = self.basic_aug.apply_brightness_modulation(image)\n",
    "            elif transform_name == \"contrast\": \n",
    "                image = self.basic_aug.apply_contrast_modulation(image)\n",
    "            \n",
    "            # [수정됨] 색상 정보 보존을 위해 색온도 변조를 주석 처리\n",
    "            # elif transform_name == \"color_temperature\":\n",
    "            #     image = self.basic_aug.apply_color_temperature_modulation(image)\n",
    "            \n",
    "            elif transform_name == \"gaussian_blur\":\n",
    "                image = self.basic_aug.apply_gaussian_blur(image)\n",
    "            elif transform_name == \"horizontal_flip\":\n",
    "                image = self.basic_aug.apply_horizontal_flip(image)\n",
    "            elif transform_name == \"stochastic_crop\":\n",
    "                image = self.basic_aug.apply_stochastic_crop_resize(image)\n",
    "            elif transform_name == \"lighting_condition\":\n",
    "                image = self.advanced_aug.apply_lighting_condition_simulation(image)\n",
    "            elif transform_name == \"shadow_glare\":\n",
    "                image = self.advanced_aug.apply_shadow_and_glare_effects(image)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51306693-c38a-4fa4-9574-8797eaee9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2  # [V4] '선 긋기' 로직을 위해 cv2 임포트\n",
    "\n",
    "# =============================================================================\n",
    "# [V4 수정] 원본 데이터셋 클래스 (UrinKitSetDataset)\n",
    "# - 'cv2.fitLine'을 사용하여 회전에 강인한(Rotation-Invariant) 정렬 로직 적용\n",
    "# =============================================================================\n",
    "class UrinKitSetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    11개 센서 패드를 하나의 세트로 처리하는 데이터셋 (V4 - 방향 벡터 정렬)\n",
    "    - 0번 라벨(딥스틱)과 1번 라벨(패드)을 ID 기준으로 분리\n",
    "    - 11개 패드의 중심점을 cv2.fitLine으로 분석하여 방향과 상관없이 정렬\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, image_size=224):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) if not d.startswith('.') and os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        self.valid_kits = []  # (img_path, label_path, class_idx, kit_idx)\n",
    "        self._collect_valid_kits()\n",
    "    \n",
    "    def _get_labels_from_txt(self, label_path, img_w, img_h):\n",
    "        \"\"\"[V4] YOLO .txt 라벨을 읽어 [x1, y1, x2, y2, cls_id] 리스트로 반환\"\"\"\n",
    "        if not os.path.exists(label_path):\n",
    "            return np.array([])\n",
    "            \n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = [l.strip() for l in f.readlines()]\n",
    "        \n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                cls_id_float, x, y, w_norm, h_norm = map(float, line.split())\n",
    "                cls_id = int(cls_id_float) # 0.0 -> 0, 1.0 -> 1\n",
    "                \n",
    "                x1 = (x - w_norm / 2) * img_w\n",
    "                y1 = (y - h_norm / 2) * img_h\n",
    "                x2 = (x + w_norm / 2) * img_w\n",
    "                y2 = (y + h_norm / 2) * img_h\n",
    "                \n",
    "                labels.append([x1, y1, x2, y2, cls_id])\n",
    "            except Exception as e:\n",
    "                print(f\"  [경고] 라벨 파싱 오류 {label_path}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        return np.array(labels)\n",
    "\n",
    "    def _collect_valid_kits(self):\n",
    "        \"\"\"[V4] ID 기반으로 11개 센서가 모두 있는 유효한 키트들 수집\"\"\"\n",
    "        print(\"유효한 센서 세트 정보 수집 중... (V4 - ID 기준)\")\n",
    "        \n",
    "        for cls in tqdm(self.classes, desc=\"클래스 처리\"):\n",
    "            cls_path = os.path.join(self.root_dir, cls)\n",
    "            if not os.path.isdir(cls_path):\n",
    "                continue\n",
    "\n",
    "            for root, _, files in os.walk(cls_path):\n",
    "                images = [f for f in files if f.endswith('.jpg')]\n",
    "                \n",
    "                for img_file in images:\n",
    "                    img_path = os.path.join(root, img_file)\n",
    "                    label_path = img_path.replace(\".jpg\", \".txt\")\n",
    "                    \n",
    "                    try:\n",
    "                        # (이미지 크기만 확인)\n",
    "                        with Image.open(img_path) as img:\n",
    "                            img_w, img_h = img.size\n",
    "                        \n",
    "                        labels = self._get_labels_from_txt(label_path, img_w, img_h)\n",
    "                        \n",
    "                        if len(labels) == 0:\n",
    "                            continue\n",
    "\n",
    "                        # [V4 수정] cls_id로 딥스틱(0)과 센서(1) 분리\n",
    "                        dipstick_boxes = labels[labels[:, 4] == 0] # cls_id == 0\n",
    "                        sensor_boxes = labels[labels[:, 4] == 1]   # cls_id == 1\n",
    "                        \n",
    "                        if len(dipstick_boxes) == 0 or len(sensor_boxes) < 11:\n",
    "                            continue\n",
    "                        \n",
    "                        # X좌표로 딥스틱 정렬 (kit_idx의 안정적 순서 확보)\n",
    "                        dipstick_boxes = dipstick_boxes[np.lexsort((dipstick_boxes[:,1], dipstick_boxes[:,0]))]\n",
    "                        \n",
    "                        # 각 딥스틱(0번)에 대해 11개 센서(1번)가 있는지 확인\n",
    "                        for kit_idx, kit in enumerate(dipstick_boxes):\n",
    "                            x1, y1, x2, y2, _ = kit\n",
    "                            \n",
    "                            mask = ((sensor_boxes[:, 0] > x1) & (sensor_boxes[:, 0] < x2) & \n",
    "                                    (sensor_boxes[:, 1] > y1) & (sensor_boxes[:, 1] < y2))\n",
    "                            group = sensor_boxes[mask]\n",
    "                            \n",
    "                            if len(group) == 11:  # 정확히 11개 센서가 있는 경우만\n",
    "                                self.valid_kits.append((\n",
    "                                    img_path, label_path, \n",
    "                                    self.class_to_idx[cls], kit_idx\n",
    "                                ))\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"이미지 처리 오류 {img_path}: {e}\")\n",
    "                        continue\n",
    "        \n",
    "        print(f\"총 {len(self.valid_kits)}개 유효한 센서 세트 발견 (V4)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_kits)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        [V4] '선 긋기' (fitLine) 로직을 적용하여 11개 센서 세트를\n",
    "        방향과 상관없이 올바른 순서(0~10)로 정렬하여 반환\n",
    "        \"\"\"\n",
    "        img_path, label_path, class_idx, kit_idx = self.valid_kits[idx]\n",
    "        \n",
    "        # 1. 이미지 로드\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        np_image = np.array(image)\n",
    "        img_w, img_h = image.size\n",
    "\n",
    "        # 2. YOLO 라벨 파싱 (ID 기준)\n",
    "        labels = self._get_labels_from_txt(label_path, img_w, img_h)\n",
    "        \n",
    "        dipstick_boxes = labels[labels[:, 4] == 0] # cls_id == 0\n",
    "        sensor_boxes = labels[labels[:, 4] == 1]   # cls_id == 1\n",
    "        \n",
    "        # _collect_valid_kits와 동일한 순서 보장\n",
    "        dipstick_boxes = dipstick_boxes[np.lexsort((dipstick_boxes[:,1], dipstick_boxes[:,0]))]\n",
    "        \n",
    "        # 3. 현재 키트의 11개 센서 추출\n",
    "        current_kit = dipstick_boxes[kit_idx]\n",
    "        x1, y1, x2, y2, _ = current_kit\n",
    "        mask = ((sensor_boxes[:, 0] > x1) & (sensor_boxes[:, 0] < x2) & \n",
    "                (sensor_boxes[:, 1] > y1) & (sensor_boxes[:, 1] < y2))\n",
    "        group = sensor_boxes[mask]\n",
    "        \n",
    "        if len(group) != 11:\n",
    "            # 이 오류가 발생하면 _collect_valid_kits와 로직이 안 맞는 것임\n",
    "            raise ValueError(f\"키트에서 11개 패드를 찾지 못했습니다 (찾은 개수: {len(group)})! 경로: {img_path}\")\n",
    "\n",
    "        # 4. [!!! V4 핵심 로직: \"선 긋기\" (Line Fitting) !!!]\n",
    "        \n",
    "        # (a) 11개 패드의 중심점 계산\n",
    "        centers = np.array([\n",
    "            ((p[0] + p[2]) / 2, (p[1] + p[3]) / 2) for p in group\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # (b) 11개 점을 통과하는 최적의 \"선(방향 벡터)\" 계산\n",
    "        [vx, vy, x0, y0] = cv2.fitLine(centers, cv2.DIST_L2, 0, 0.01, 0.01)\n",
    "        direction_vector = np.array([vx[0], vy[0]])\n",
    "        line_origin = np.array([x0[0], y0[0]])\n",
    "\n",
    "        # (c) 11개 중심점을 이 \"선\"에 투영(dot product)시켜 1차원 거리값 계산\n",
    "        projected_distances = []\n",
    "        for center in centers:\n",
    "            distance = np.dot(center - line_origin, direction_vector)\n",
    "            projected_distances.append(distance)\n",
    "        \n",
    "        # (d) 이 \"거리값\"을 기준으로 패드들을 정렬 (0~10번 순서 확정)\n",
    "        sort_indices = np.argsort(projected_distances)\n",
    "        sorted_group = group[sort_indices]\n",
    "\n",
    "        # 5. 정렬된 11개 센서 크롭해서 세트 구성\n",
    "        patches = []\n",
    "        for patch in sorted_group: # [V4] 정렬된 그룹 사용\n",
    "            px1, py1, px2, py2, _ = patch\n",
    "            \n",
    "            # (수정) 원본 코드의 ::-1 (BGR 변환)은 PIL.Image.fromarray가\n",
    "            # 어차피 RGB로 처리하므로 제거함 (혼동 방지)\n",
    "            cropped = np_image[round(py1):round(py2), round(px1):round(px2)]\n",
    "            cropped_pil = Image.fromarray(cropped)\n",
    "            \n",
    "            transformed = self.transform(cropped_pil)\n",
    "            patches.append(transformed)\n",
    "        \n",
    "        # 11개 센서를 하나의 텐서로 스택 (이제 0~10번 순서가 보장됨)\n",
    "        X = torch.stack(patches)\n",
    "        Y = torch.tensor(class_idx)\n",
    "        \n",
    "        return X, Y\n",
    "        \n",
    "def preprocess_and_save_data(data_dirs, save_paths, image_size=224):\n",
    "    \"\"\"\n",
    "    각 데이터셋(train/val/test)별로 센서 세트 데이터 전처리하여 파일로 저장\n",
    "    \n",
    "    Args:\n",
    "        data_dirs: {'train': path, 'val': path, 'test': path}\n",
    "        save_paths: {'train': path, 'val': path, 'test': path}\n",
    "    \"\"\"\n",
    "    for split_name, data_dir in data_dirs.items():\n",
    "        if not os.path.exists(data_dir):\n",
    "            print(f\"경고: {split_name} 데이터 폴더가 존재하지 않습니다: {data_dir}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{split_name} 센서 세트 데이터 전처리 시작...\")\n",
    "        dataset = UrinKitSetDataset(data_dir, image_size)\n",
    "        \n",
    "        preprocessed_data = []\n",
    "        for i in tqdm(range(len(dataset)), desc=f\"{split_name} 센서 세트 전처리\"):\n",
    "            try:\n",
    "                sensor_set, label = dataset[i]  # (11, 3, 224, 224)\n",
    "                preprocessed_data.append((sensor_set, label))\n",
    "            except Exception as e:\n",
    "                print(f\"전처리 오류 인덱스 {i}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        save_path = save_paths[split_name]\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(preprocessed_data, f)\n",
    "        \n",
    "        print(f\"{split_name} 전처리 완료: {len(preprocessed_data)}개 센서 세트 저장됨\")\n",
    "\n",
    "def create_argumented_datasets(base_train_dataset, base_val_dataset, base_test_dataset):\n",
    "    \n",
    "    # [수정] 훈련 데이터 증강 팩터를 15 -> 1로 변경\n",
    "    train_dataset = NaturePaperStyleDataset(\n",
    "        base_train_dataset, \n",
    "        augmentation_level=\"all_surroundings\",\n",
    "        augmentation_factor=1  # <-- 15에서 1로 수정\n",
    "    )\n",
    "    \n",
    "    # 검증/테스트: 증강 없음 (기존과 동일)\n",
    "    val_dataset = NaturePaperStyleDataset(\n",
    "        base_val_dataset,\n",
    "        augmentation_level=\"single_light\", \n",
    "        augmentation_factor=1\n",
    "    )\n",
    "    \n",
    "    test_dataset = NaturePaperStyleDataset(\n",
    "        base_test_dataset,\n",
    "        augmentation_level=\"single_light\",\n",
    "        augmentation_factor=1\n",
    "    )\n",
    "    \n",
    "    print(f\"훈련 데이터: {len(train_dataset):,}개 (원본 {len(base_train_dataset):,}개)\")\n",
    "    print(f\"검증 데이터: {len(val_dataset):,}개\") \n",
    "    print(f\"테스트 데이터: {len(test_dataset):,}개\")\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "675041fd-7db6-4e8c-9e67-c51804a479d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ensorSetClassifier\n",
    "# - 11개의 Specialist Expert 백본\n",
    "# - 6개의 보조 분류기\n",
    "# =============================================================================\n",
    "\n",
    "class SensorSetClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    [Path 1] 개별 전문가 (6개)\n",
    "        - 0, 1, 4, 5, 6, 7번 백본의 특징이 6개의 개별 MLP로 전달됨\n",
    "        - 6개의 출력 생성\n",
    "    \n",
    "    [Path 2] 어텐션 (1개)\n",
    "        - 11개 백본 특징 + 1개 CLS 토큰 (총 12개)\n",
    "        - Transformer로 전달되어 1개의 Main Output 생성\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 model_name: str, \n",
    "                 feature_dim: int,\n",
    "                 num_classes_main: int, # 메인 출력 (33개)\n",
    "                 aux_classes_groups: dict, # 보조 출력 (6개 그룹)\n",
    "                 num_sensors=11, \n",
    "                 nhead=8, \n",
    "                 num_encoder_layers=2, \n",
    "                 dim_feedforward=1024, \n",
    "                 dropout=0.1,\n",
    "                 pretrained=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_classes_main = num_classes_main\n",
    "        self.aux_classes_groups = aux_classes_groups\n",
    "        self.num_sensors = num_sensors\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # --- 1. 백본 생성 (11개 Specialist) ---\n",
    "        # 11개의 개별 백본 (3-channel input)\n",
    "        print(f\"  [Specialist Experts] 생성 중 (x11, 입력: 3채널)...\")\n",
    "        self.backbones = nn.ModuleList(\n",
    "            [timm.create_model(model_name, pretrained=pretrained) for _ in range(num_sensors)]\n",
    "        )\n",
    "        \n",
    "        # 특징 차원 검증\n",
    "        actual_features = self.backbones[0].num_features\n",
    "        if actual_features != self.feature_dim:\n",
    "            print(f\"    특징 차원 조정: {self.feature_dim} → {actual_features}\")\n",
    "            self.feature_dim = actual_features\n",
    "        \n",
    "        for backbone in self.backbones:\n",
    "            backbone.reset_classifier(0)\n",
    "        \n",
    "        # 풀링\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # --- 2. [Path 2] 통합 전문가용 모듈 ---\n",
    "        # [CLS] 토큰\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, self.feature_dim))\n",
    "        \n",
    "        # Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.feature_dim, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # [Path 2] 메인 분류기 (Transformer의 CLS 토큰을 입력받음)\n",
    "        self.main_classifier = nn.Sequential(\n",
    "            nn.LayerNorm(self.feature_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.feature_dim, self.num_classes_main) # (예: 33개 출력)\n",
    "        )\n",
    "\n",
    "        # --- 3. [Path 1]  ---\n",
    "        print(f\"  [Auxiliary Heads] 생성 중 (x6, 개별 expert)...\")\n",
    "        self.aux_heads = nn.ModuleDict()\n",
    "        \n",
    "        # aux_classes_groups 딕셔너리 (예: {'aux_0': [...], 'aux_1': [...]})를 기반으로\n",
    "        # 6개의 보조 분류기(MLP)를 동적으로 생성\n",
    "        for group_name, classes_list in self.aux_classes_groups.items():\n",
    "            num_aux_classes = len(classes_list)\n",
    "            pad_index = int(group_name.split('_')[-1]) # 'aux_0' -> 0\n",
    "            \n",
    "            # 간단한 2-Layer MLP\n",
    "            head = nn.Sequential(\n",
    "                nn.LayerNorm(self.feature_dim),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(self.feature_dim, self.feature_dim // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(self.feature_dim // 2),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(self.feature_dim // 2, num_aux_classes) # (예: Hemo 7개 출력)\n",
    "            )\n",
    "            \n",
    "            self.aux_heads[group_name] = head\n",
    "            print(f\"    - {group_name} (패드 {pad_index}번 담당) 생성 완료 (출력: {num_aux_classes}개)\")\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C, H, W = x.shape # B, 11, 3, 224, 224\n",
    "        \n",
    "        # --- 1. 백본 특징 추출 ---\n",
    "        # [Specialist Experts] (11개)\n",
    "        patch_features = []\n",
    "        for i in range(self.num_sensors):\n",
    "            patch_input = x[:, i, :, :, :]\n",
    "            patch_backbone = self.backbones[i]\n",
    "            features = patch_backbone.forward_features(patch_input)\n",
    "            pooled = self.pool(features).flatten(1) # (B, D)\n",
    "            patch_features.append(pooled)\n",
    "            \n",
    "        seq_features = torch.stack(patch_features, dim=1) # (B, 11, D)\n",
    "\n",
    "        # --- 2. [Path 1] 보조 출력 계산 ---\n",
    "        \n",
    "        aux_outputs = {}\n",
    "        # 6개의 보조 헤드(MLP)에 대해 반복\n",
    "        for group_name, head_mlp in self.aux_heads.items():\n",
    "            # 'aux_0' -> 0번 인덱스 추출\n",
    "            pad_index = int(group_name.split('_')[-1]) \n",
    "            \n",
    "            # (B, 11, D)에서 해당 패드의 특징(B, D)을 가져옴\n",
    "            expert_feature = seq_features[:, pad_index, :]\n",
    "            \n",
    "            # MLP를 통과시켜 보조 출력 계산\n",
    "            aux_outputs[group_name] = head_mlp(expert_feature)\n",
    "        \n",
    "        # --- 3. [Path 2] 메인 출력 계산 ---\n",
    "        \n",
    "        # Transformer 입력 준비 (1 + 11 = 12 tokens)\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1) # (B, 1, D)\n",
    "        \n",
    "        # shared_token 제거\n",
    "        # (B, 1, D) + (B, 11, D)\n",
    "        seq_with_tokens = torch.cat((cls_tokens, seq_features), dim=1) # (B, 12, D)\n",
    "        \n",
    "        # Transformer & Classifier\n",
    "        contextual_features = self.transformer_encoder(seq_with_tokens) # (B, 12, D)\n",
    "        cls_output = contextual_features[:, 0] # (B, D)\n",
    "        main_output = self.main_classifier(cls_output)\n",
    "        \n",
    "        # --- 4. 7개 출력 모두 반환 ---\n",
    "        return main_output, aux_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6c6a33-ef49-405f-b865-eb9daa523ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# train_model & evaluate_model\n",
    "# - 7개의 Loss를 합산하여 학습\n",
    "# =============================================================================\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, num_epochs=50, lr=1e-4, \n",
    "                version=\"mtl_model\", aux_loss_weight=0.5):\n",
    "    \"\"\"\n",
    "    MTL 모델 학습 및 검증 함수\n",
    "    - L_total = L_main + aux_loss_weight * (sum(L_aux))\n",
    "    \"\"\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"{torch.cuda.device_count()}개 GPU 병렬 처리 설정\")\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # --- 1. 손실 함수 7개 정의 ---\n",
    "    \n",
    "    # [Path 2] 메인 Loss (33개 클래스용)\n",
    "    criterion_main = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # [Path 1] 보조 Loss (6개 전문가용)\n",
    "    # 5개 일반 전문가 (Hemo, Bili, Protein, Nitrite, Glucose)\n",
    "    criterion_aux = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # 1개 pH (Loss 계산 시 -1 라벨(IGNORE) 무시)\n",
    "    criterion_aux_ph = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    \n",
    "    # 보조 Loss 딕셔너리\n",
    "    criteria_aux = {\n",
    "        'aux_0': criterion_aux,\n",
    "        'aux_1': criterion_aux,\n",
    "        'aux_4': criterion_aux,\n",
    "        'aux_5': criterion_aux,\n",
    "        'aux_6': criterion_aux,\n",
    "        'aux_7': criterion_aux_ph # pH만 ignore_index 적용\n",
    "    }\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # 보조 라벨 인덱스 (데이터로더에서 3번째 반환값)\n",
    "    # Y_aux는 (B, 6) 형태, (hemo, bili, protein, nitrite, glucose, ph) 순서\n",
    "    AUX_LABEL_KEYS = ['aux_0', 'aux_1', 'aux_4', 'aux_5', 'aux_6', 'aux_7']\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # ====================\n",
    "        #  학습 (Training)\n",
    "        # ====================\n",
    "        model.train()\n",
    "        total_loss_main = 0.0\n",
    "        total_loss_aux = 0.0\n",
    "        \n",
    "        # 7개 정확도 추적\n",
    "        correct_counts = {'main': 0}\n",
    "        total_counts = {'main': 0}\n",
    "        for key in AUX_LABEL_KEYS:\n",
    "            correct_counts[key] = 0\n",
    "            total_counts[key] = 0\n",
    "\n",
    "        \n",
    "        for batch_idx, (X, Y_main, Y_aux) in enumerate(tqdm(train_loader, desc=f\"[Epoch {epoch+1}] Training\")):\n",
    "            X, Y_main, Y_aux = X.to(device), Y_main.to(device), Y_aux.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # --- 2. 7개 출력 계산 ---\n",
    "            main_output, aux_outputs = model(X)\n",
    "            \n",
    "            # --- 3. 7개 Loss 계산 ---\n",
    "            # [Path 2] 메인 Loss\n",
    "            loss_main = criterion_main(main_output, Y_main)\n",
    "            \n",
    "            # [Path 1] 6개 보조 Loss\n",
    "            loss_aux_total = 0.0\n",
    "            for i, key in enumerate(AUX_LABEL_KEYS):\n",
    "                # Y_aux (B, 6)에서 i번째 라벨 (B,) 추출\n",
    "                y_aux_target = Y_aux[:, i]\n",
    "                \n",
    "                # 해당 보조 헤드의 Loss 함수 사용\n",
    "                loss_fn = criteria_aux[key] \n",
    "                loss_aux = loss_fn(aux_outputs[key], y_aux_target)\n",
    "                \n",
    "                # pH의 경우, 라벨이 -1이 아닌 샘플에 대해서만 정확도 계산\n",
    "                if key == 'aux_7':\n",
    "                    valid_mask = (y_aux_target != -1)\n",
    "                    if valid_mask.sum() > 0:\n",
    "                        _, predicted_aux = torch.max(aux_outputs[key][valid_mask], 1)\n",
    "                        correct_counts[key] += (predicted_aux == y_aux_target[valid_mask]).sum().item()\n",
    "                        total_counts[key] += valid_mask.sum().item()\n",
    "                else: # 나머지 5개 전문가\n",
    "                    _, predicted_aux = torch.max(aux_outputs[key], 1)\n",
    "                    correct_counts[key] += (predicted_aux == y_aux_target).sum().item()\n",
    "                    total_counts[key] += y_aux_target.size(0)\n",
    "\n",
    "                loss_aux_total += loss_aux\n",
    "            \n",
    "            # --- 4. 최종 Loss 합산 및 역전파 ---\n",
    "            loss_total = loss_main + aux_loss_weight * loss_aux_total\n",
    "            \n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss_main += loss_main.item()\n",
    "            total_loss_aux += loss_aux_total.item()\n",
    "            \n",
    "            # 메인 정확도 계산\n",
    "            _, predicted_main = torch.max(main_output, 1)\n",
    "            correct_counts['main'] += (predicted_main == Y_main).sum().item()\n",
    "            total_counts['main'] += Y_main.size(0)\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                clear_gpu_memory()\n",
    "        \n",
    "        # 에포크 평균 Loss 및 정확도\n",
    "        avg_loss_main = total_loss_main / len(train_loader)\n",
    "        avg_loss_aux = total_loss_aux / len(train_loader)\n",
    "        train_acc_main = 100.0 * correct_counts['main'] / total_counts['main']\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  [Train] Total Loss: {(avg_loss_main + avg_loss_aux):.4f} (Main: {avg_loss_main:.4f} + Aux: {avg_loss_aux:.4f})\")\n",
    "        print(f\"  [Train] Main Acc: {train_acc_main:.2f}%\")\n",
    "        \n",
    "        # 보조 정확도 출력\n",
    "        for key in AUX_LABEL_KEYS:\n",
    "            if total_counts[key] > 0: # (pH가 -1만 있는 배치를 거르기 위함)\n",
    "                acc = 100.0 * correct_counts[key] / total_counts[key]\n",
    "                print(f\"    - Aux Acc ({key}): {acc:.2f}%\")\n",
    "\n",
    "        # ======================\n",
    "        #  검증 단계 (Validation)\n",
    "        # ======================\n",
    "        # (메인 정확도만 계산 - 간결함을 위해)\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (X, Y_main, Y_aux) in tqdm(val_loader, desc=f\"[Epoch {epoch+1}] Validation\"):\n",
    "                X, Y_main = X.to(device), Y_main.to(device)\n",
    "                \n",
    "                # 7개 출력 중 메인 출력(main_output)만 사용\n",
    "                main_output, _ = model(X) \n",
    "                \n",
    "                _, predicted = torch.max(main_output, 1)\n",
    "                correct += (predicted == Y_main).sum().item()\n",
    "                total += Y_main.size(0)\n",
    "        \n",
    "        val_acc = 100.0 * correct / total\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f\"  [Val] Main Acc: {val_acc:.2f}%\\n\")\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            save_path = f'./models/{version}_weight/best_mtl_classifier_epoc{epoch+1}_{val_acc:.2f}.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model_to_save.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc\n",
    "            }, save_path)\n",
    "            print(f\"  ⭐ 최고 성능 모델 저장됨 (Val Acc: {val_acc:.2f}%) ⭐\\n\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        clear_gpu_memory()\n",
    "    \n",
    "    return model, best_val_acc\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, version=\"mtl_model\"):\n",
    "    \"\"\"\n",
    "    MTL 모델 성능 평가 및 7개 혼동행렬(CM) 생성\n",
    "    [시각화 수정] \n",
    "    - 33x33 메인 CM의 크기를 클래스 개수에 비례하여 동적으로 조절\n",
    "    - plt.tight_layout() 제거 (savefig의 bbox_inches='tight'로 대체)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 7개 경로의 예측값과 실제 라벨을 저장할 리스트\n",
    "    all_preds = {'main': []}\n",
    "    all_labels = {'main': []}\n",
    "    AUX_LABEL_KEYS = ['aux_0', 'aux_1', 'aux_4', 'aux_5', 'aux_6', 'aux_7']\n",
    "    for key in AUX_LABEL_KEYS:\n",
    "        all_preds[key] = []\n",
    "        all_labels[key] = []\n",
    "        \n",
    "    print(\"모델 성능 평가 중 (7개 경로 동시 평가)...\")\n",
    "    with torch.no_grad():\n",
    "        for (X, Y_main, Y_aux) in tqdm(test_loader, desc=\"평가 진행\"):\n",
    "            X, Y_main, Y_aux = X.to(device), Y_main.to(device), Y_aux.to(device)\n",
    "            \n",
    "            # --- 1. 7개 출력 계산 ---\n",
    "            main_output, aux_outputs = model(X)\n",
    "            \n",
    "            # --- 2. 메인 경로 결과 저장 ---\n",
    "            _, predicted_main = torch.max(main_output, 1)\n",
    "            all_preds['main'].extend(predicted_main.cpu().numpy())\n",
    "            all_labels['main'].extend(Y_main.cpu().numpy())\n",
    "            \n",
    "            # --- 3. 6개 보조 경로 결과 저장 ---\n",
    "            for i, key in enumerate(AUX_LABEL_KEYS):\n",
    "                y_aux_target = Y_aux[:, i]\n",
    "                _, predicted_aux = torch.max(aux_outputs[key], 1)\n",
    "                \n",
    "                # pH의 경우, -1 라벨은 평가에서 제외\n",
    "                if key == 'aux_7':\n",
    "                    valid_mask = (y_aux_target != -1)\n",
    "                    if valid_mask.sum() > 0:\n",
    "                        all_preds[key].extend(predicted_aux[valid_mask].cpu().numpy())\n",
    "                        all_labels[key].extend(y_aux_target[valid_mask].cpu().numpy())\n",
    "                else:\n",
    "                    all_preds[key].extend(predicted_aux.cpu().numpy())\n",
    "                    all_labels[key].extend(y_aux_target.cpu().numpy())\n",
    "\n",
    "    # --- 4. 7개 정확도 계산 및 출력 ---\n",
    "    results = {'accuracies': {}, 'confusion_matrices': {}}\n",
    "    \n",
    "    print(\"\\n--- [최종 테스트 결과] ---\")\n",
    "    \n",
    "    # 메인 정확도\n",
    "    acc_main = 100.0 * (np.array(all_preds['main']) == np.array(all_labels['main'])).sum() / len(all_labels['main'])\n",
    "    results['accuracies']['main'] = acc_main\n",
    "    print(f\"  ⭐ [Main] 최종 테스트 정확도: {acc_main:.2f}%\")\n",
    "    \n",
    "    # 보조 정확도\n",
    "    for key in AUX_LABEL_KEYS:\n",
    "        if len(all_labels[key]) > 0:\n",
    "            acc_aux = 100.0 * (np.array(all_preds[key]) == np.array(all_labels[key])).sum() / len(all_labels[key])\n",
    "            results['accuracies'][key] = acc_aux\n",
    "            print(f\"    - [Aux {key}] 전문가 정확도: {acc_aux:.2f}%\")\n",
    "        else:\n",
    "            print(f\"    - [Aux {key}] 전문가 정확도: N/A (유효 샘플 없음)\")\n",
    "\n",
    "    # --- 5. [논문용] 7개 혼동행렬(CM) 생성 및 저장 ---\n",
    "\n",
    "    print(\"\\n[논문용] 7개 혼동 행렬(Confusion Matrix) 생성 중...\")\n",
    "    \n",
    "    # CM 저장 디렉토리\n",
    "    cm_save_dir = f'./results/{version}_result'\n",
    "    os.makedirs(cm_save_dir, exist_ok=True)\n",
    "    \n",
    "    # (a) 메인 CM (33x33)\n",
    "    try:\n",
    "        class_names_main = MAIN_CLASSES # [신규 셀]에서 정의됨\n",
    "        labels_main = list(range(len(class_names_main)))\n",
    "        cm_main = confusion_matrix(all_labels['main'], all_preds['main'], labels=labels_main)\n",
    "        results['confusion_matrices']['main'] = cm_main\n",
    "        \n",
    "        # [!!! 수정 1 !!!]\n",
    "        # 클래스 개수에 따라 그림 크기를 동적으로 조절 (글자 겹침 방지)\n",
    "        # 33개 클래스 * 0.8 = 약 26.4인치. 최소 20인치 보장.\n",
    "        fig_size_main = max(20, len(class_names_main) * 0.8) \n",
    "        plt.figure(figsize=(fig_size_main, fig_size_main))\n",
    "        \n",
    "        disp_main = ConfusionMatrixDisplay(confusion_matrix=cm_main, display_labels=class_names_main)\n",
    "        \n",
    "        # [!!! 수정 2 !!!]\n",
    "        # text_kw={'size': 6} : 매트릭스 내부 숫자 폰트 크기 6pt로 줄임\n",
    "        disp_main.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', text_kw={'size': 6})\n",
    "        \n",
    "        plt.title(\"Main Classifier (33 Classes) - Confusion Matrix\")\n",
    "        \n",
    "        # [!!! 수정 3 !!!]\n",
    "        # plt.tight_layout() 제거 -> bbox_inches='tight'가 알아서 처리\n",
    "        \n",
    "        plt.savefig(os.path.join(cm_save_dir, 'confusion_matrix_main.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close() # 메모리 해제\n",
    "        print(f\"  - (1/7) Main CM 저장 완료.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - (1/7) Main CM 생성 오류: {e}\")\n",
    "\n",
    "    # (b) 6개 보조 CM (기존과 동일 - 이미 동적 크기 조절이 적용되어 있음)\n",
    "    for i, key in enumerate(AUX_LABEL_KEYS):\n",
    "        try:\n",
    "            if len(all_labels[key]) == 0:\n",
    "                print(f\"  - ({i+2}/7) Aux CM ({key}) 건너뜀 (유효 샘플 없음).\")\n",
    "                continue\n",
    "            \n",
    "            class_names_aux = AUX_CLASSES_GROUPS[key] # [신규 셀]에서 정의됨\n",
    "            labels_aux = list(range(len(class_names_aux)))\n",
    "            cm_aux = confusion_matrix(all_labels[key], all_preds[key], labels=labels_aux)\n",
    "            results['confusion_matrices'][key] = cm_aux\n",
    "            \n",
    "            # (이 로직은 이미 동적이므로 수정할 필요 없음)\n",
    "            fig_size = max(6, len(class_names_aux) * 0.8) \n",
    "            plt.figure(figsize=(fig_size, fig_size))\n",
    "            \n",
    "            disp_aux = ConfusionMatrixDisplay(confusion_matrix=cm_aux, display_labels=class_names_aux)\n",
    "            disp_aux.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "            plt.title(f\"Auxiliary Classifier ({key}) - Confusion Matrix\")\n",
    "            \n",
    "            # [!!! 수정 4 !!!] (일관성을 위해)\n",
    "            # plt.tight_layout() 제거\n",
    "            \n",
    "            plt.savefig(os.path.join(cm_save_dir, f'confusion_matrix_{key}.png'), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"  - ({i+2}/7) Aux CM ({key}) 저장 완료.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - ({i+2}/7) Aux CM ({key}) 생성 오류: {e}\")\n",
    "\n",
    "    print(\"모든 평가 및 시각화 완료.\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4970b181-474b-491a-814b-6d6303a9bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 메인\n",
    "# =============================================================================\n",
    "\n",
    "# ===================================\n",
    "VERSION = \"9_1_mobilevit_xs\" \n",
    "# ===================================\n",
    "    \n",
    "# 디렉토리 자동 생성mobilenet v3\n",
    "os.makedirs(f'./models/{VERSION}_weight', exist_ok=True)\n",
    "os.makedirs(f'./results/{VERSION}_result', exist_ok=True)\n",
    "os.makedirs(f'./preprocessed/mcc2_filtered_preprocessed', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a692b9d9-a2f4-46e1-9440-92aecd8be0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 장치: cuda\n",
      "사용 가능한 GPU 수: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"사용 장치: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"사용 가능한 GPU 수: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4675e189-effe-4e9b-840a-5fb2eca56ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "data_dirs = {\n",
    "    'train': './dataset_mcc/train',\n",
    "    'val': './dataset_mcc/val', \n",
    "    'test': './dataset_mcc/test'\n",
    "}\n",
    "\n",
    "# 전처리된 데이터 저장 경로\n",
    "preprocessed_paths = {\n",
    "    'train': f'./preprocessed/mcc2_preprocessed/train_sensor_sets.pkl',\n",
    "    'val': f'./preprocessed/mcc2_preprocessed/val_sensor_sets.pkl',\n",
    "    'test': f'./preprocessed/mcc2_preprocessed/test_sensor_sets.pkl'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ad7a42-033a-4876-93da-d57dd5752bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 전처리 데이터 사용\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 (처음 실행시에만)\n",
    "need_preprocessing = any(not os.path.exists(path) for path in preprocessed_paths.values())\n",
    "\n",
    "if need_preprocessing:\n",
    "    print(\"전처리된 데이터 없음. 전처리 시작\")\n",
    "    preprocess_and_save_data(data_dirs, preprocessed_paths, image_size=224)\n",
    "else:\n",
    "    print(\"기존 전처리 데이터 사용\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4121af80-8f97-4981-993b-b8a4ed85b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 데이터 준비 완료: 4564개 센서 세트 (MTL 모드)\n",
      "HDF5 데이터 준비 완료: 1137개 센서 세트 (MTL 모드)\n",
      "HDF5 데이터 준비 완료: 1140개 센서 세트 (MTL 모드)\n",
      "훈련 데이터: 27,384개\n",
      "검증 데이터: 1,137개\n",
      "테스트 데이터: 1,140개\n",
      "\n",
      "[클래스 자동 탐색 완료]\n",
      "총 33개의 클래스를 './dataset_mcc/train'에서 발견했습니다.\n"
     ]
    }
   ],
   "source": [
    "# HDF5 파일 경로\n",
    "h5_paths = {\n",
    "    'train': f'./preprocessed/mcc2_preprocessed/train_sensor_sets.h5',\n",
    "    'val': f'./preprocessed/mcc2_preprocessed/val_sensor_sets.h5',\n",
    "    'test': f'./preprocessed/mcc2_preprocessed/test_sensor_sets.h5'\n",
    "}\n",
    "\n",
    "# Pickle → HDF5 변환 (한 번만 실행)\n",
    "for split_name, pickle_path in preprocessed_paths.items():\n",
    "    h5_path = h5_paths[split_name]\n",
    "    if not os.path.exists(h5_path):\n",
    "        convert_pickle_to_hdf5(pickle_path, h5_path)\n",
    "\n",
    "# HDF5 데이터셋 로드 (메모리 효율적)\n",
    "base_train_dataset = HDF5UrinKitDataset(h5_paths['train'])\n",
    "base_val_dataset = HDF5UrinKitDataset(h5_paths['val']) \n",
    "base_test_dataset = HDF5UrinKitDataset(h5_paths['test'])\n",
    "\n",
    "# 증강 데이터셋 생성\n",
    "train_dataset = NaturePaperStyleDataset(\n",
    "    base_train_dataset, \n",
    "    augmentation_level=\"all_surroundings\",\n",
    "    augmentation_factor=6\n",
    ")\n",
    "\n",
    "val_dataset = NaturePaperStyleDataset(\n",
    "    base_val_dataset,\n",
    "    augmentation_level=\"single_light\", \n",
    "    augmentation_factor=1\n",
    ")\n",
    "\n",
    "test_dataset = NaturePaperStyleDataset(\n",
    "    base_test_dataset,\n",
    "    augmentation_level=\"single_light\",\n",
    "    augmentation_factor=1\n",
    ")\n",
    "\n",
    "print(f\"훈련 데이터: {len(train_dataset):,}개\")\n",
    "print(f\"검증 데이터: {len(val_dataset):,}개\") \n",
    "print(f\"테스트 데이터: {len(test_dataset):,}개\")\n",
    "\n",
    "# 클래스 정보는 간단히 하드코딩 (UrinKitSetDataset 피하기)\n",
    "try:\n",
    "    train_dir = data_dirs['train'] # 셀 10에서 정의된 경로\n",
    "    \n",
    "    if not os.path.exists(train_dir):\n",
    "        raise NotADirectoryError(f\"Train 폴더 경로를 찾을 수 없습니다: {train_dir}\")\n",
    "        \n",
    "    class_names = sorted([d for d in os.listdir(train_dir) \n",
    "                          if not d.startswith('.') and os.path.isdir(os.path.join(train_dir, d))])\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    print(f\"\\n[클래스 자동 탐색 완료]\")\n",
    "    print(f\"총 {num_classes}개의 클래스를 '{train_dir}'에서 발견했습니다.\")\n",
    "    \n",
    "    if num_classes == 0:\n",
    "        raise Exception(\"클래스 폴더를 찾을 수 없습니다. 'data_dirs' 경로를 확인하세요.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"[오류] 클래스 탐색 실패: {e}\")\n",
    "    print(\"학습을 중단합니다.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee2eab52-2643-4a26-9199-4cded2e34ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1139f3e3-78a5-48e7-8f6e-3ac7f1d7af3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 규칙 확인: 메인 33개, 보조 6개 그룹\n",
      "  [Specialist Experts] 생성 중 (x11, 입력: 3채널)...\n",
      "    특징 차원 조정: 576 → 384\n",
      "  [Auxiliary Heads] 생성 중 (x6, 개별 expert)...\n",
      "    - aux_0 (패드 0번 담당) 생성 완료 (출력: 7개)\n",
      "    - aux_1 (패드 1번 담당) 생성 완료 (출력: 4개)\n",
      "    - aux_4 (패드 4번 담당) 생성 완료 (출력: 6개)\n",
      "    - aux_5 (패드 5번 담당) 생성 완료 (출력: 3개)\n",
      "    - aux_6 (패드 6번 담당) 생성 완료 (출력: 10개)\n",
      "    - aux_7 (패드 7번 담당) 생성 완료 (출력: 7개)\n",
      "\n",
      "✅ mobilevit_xs 백본 (x11) Multi-Task Learning 모델 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 모델 생성\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    num_classes = len(MAIN_CLASSES)\n",
    "    aux_groups = AUX_CLASSES_GROUPS\n",
    "    print(f\"라벨 규칙 확인: 메인 {num_classes}개, 보조 {len(aux_groups)}개 그룹\")\n",
    "except NameError:\n",
    "    print(\"치명적 오류: [신규 셀]의 라벨 규칙(MAIN_CLASSES 등)이 로드되지 않았습니다.\")\n",
    "    print(\"노트북의 [신규 셀]을 먼저 실행하세요.\")\n",
    "    raise\n",
    "\n",
    "MODEL_NAME = 'mobilevit_xs'\n",
    "FEATURE_DIM = 576\n",
    "\n",
    "model = SensorSetClassifier(\n",
    "    model_name=MODEL_NAME,\n",
    "    feature_dim=FEATURE_DIM,\n",
    "    num_classes_main=num_classes,       # 33개 메인 클래스 수\n",
    "    aux_classes_groups=aux_groups,      # 6개 보조 그룹 딕셔너리\n",
    "    pretrained=True                     # pretrained=True\n",
    ")\n",
    "print(f\"\\n✅ {MODEL_NAME} 백본 (x11) Multi-Task Learning 모델 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee8f7fc-1a33-461a-b57d-d15d705e1df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Training: 100%|██████████| 1712/1712 [22:56<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:\n",
      "  [Train] Total Loss: nan (Main: 1.5512 + Aux: nan)\n",
      "  [Train] Main Acc: 48.29%\n",
      "    - Aux Acc (aux_0): 87.31%\n",
      "    - Aux Acc (aux_1): 90.03%\n",
      "    - Aux Acc (aux_4): 89.14%\n",
      "    - Aux Acc (aux_5): 96.62%\n",
      "    - Aux Acc (aux_6): 79.97%\n",
      "    - Aux Acc (aux_7): 65.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Validation: 100%|██████████| 72/72 [00:48<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 68.25%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 68.25%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Training: 100%|██████████| 1712/1712 [22:35<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:\n",
      "  [Train] Total Loss: nan (Main: 0.5891 + Aux: nan)\n",
      "  [Train] Main Acc: 79.74%\n",
      "    - Aux Acc (aux_0): 94.05%\n",
      "    - Aux Acc (aux_1): 90.97%\n",
      "    - Aux Acc (aux_4): 93.25%\n",
      "    - Aux Acc (aux_5): 98.71%\n",
      "    - Aux Acc (aux_6): 90.07%\n",
      "    - Aux Acc (aux_7): 82.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Validation: 100%|██████████| 72/72 [00:17<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 79.24%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 79.24%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Training: 100%|██████████| 1712/1712 [21:56<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50:\n",
      "  [Train] Total Loss: nan (Main: 0.3176 + Aux: nan)\n",
      "  [Train] Main Acc: 89.58%\n",
      "    - Aux Acc (aux_0): 96.34%\n",
      "    - Aux Acc (aux_1): 91.24%\n",
      "    - Aux Acc (aux_4): 94.88%\n",
      "    - Aux Acc (aux_5): 99.02%\n",
      "    - Aux Acc (aux_6): 94.36%\n",
      "    - Aux Acc (aux_7): 87.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Validation: 100%|██████████| 72/72 [00:17<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 85.84%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 85.84%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Training: 100%|██████████| 1712/1712 [21:47<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50:\n",
      "  [Train] Total Loss: nan (Main: 0.2189 + Aux: nan)\n",
      "  [Train] Main Acc: 92.93%\n",
      "    - Aux Acc (aux_0): 97.18%\n",
      "    - Aux Acc (aux_1): 92.27%\n",
      "    - Aux Acc (aux_4): 95.65%\n",
      "    - Aux Acc (aux_5): 99.16%\n",
      "    - Aux Acc (aux_6): 96.10%\n",
      "    - Aux Acc (aux_7): 90.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Validation: 100%|██████████| 72/72 [00:20<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 86.10%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 86.10%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Training: 100%|██████████| 1712/1712 [21:10<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50:\n",
      "  [Train] Total Loss: nan (Main: 0.1679 + Aux: nan)\n",
      "  [Train] Main Acc: 94.53%\n",
      "    - Aux Acc (aux_0): 97.75%\n",
      "    - Aux Acc (aux_1): 93.56%\n",
      "    - Aux Acc (aux_4): 96.36%\n",
      "    - Aux Acc (aux_5): 99.29%\n",
      "    - Aux Acc (aux_6): 96.91%\n",
      "    - Aux Acc (aux_7): 94.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Validation: 100%|██████████| 72/72 [00:17<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 87.60%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 87.60%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Training: 100%|██████████| 1712/1712 [20:55<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50:\n",
      "  [Train] Total Loss: nan (Main: 0.1458 + Aux: nan)\n",
      "  [Train] Main Acc: 95.25%\n",
      "    - Aux Acc (aux_0): 98.19%\n",
      "    - Aux Acc (aux_1): 94.70%\n",
      "    - Aux Acc (aux_4): 96.84%\n",
      "    - Aux Acc (aux_5): 99.26%\n",
      "    - Aux Acc (aux_6): 97.33%\n",
      "    - Aux Acc (aux_7): 93.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Validation: 100%|██████████| 72/72 [00:17<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 88.30%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 88.30%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Training: 100%|██████████| 1712/1712 [21:57<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50:\n",
      "  [Train] Total Loss: nan (Main: 0.1188 + Aux: nan)\n",
      "  [Train] Main Acc: 96.13%\n",
      "    - Aux Acc (aux_0): 98.37%\n",
      "    - Aux Acc (aux_1): 95.64%\n",
      "    - Aux Acc (aux_4): 97.18%\n",
      "    - Aux Acc (aux_5): 99.35%\n",
      "    - Aux Acc (aux_6): 97.74%\n",
      "    - Aux Acc (aux_7): 95.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Validation: 100%|██████████| 72/72 [00:17<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 88.83%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 88.83%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Training: 100%|██████████| 1712/1712 [22:27<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50:\n",
      "  [Train] Total Loss: nan (Main: 0.1072 + Aux: nan)\n",
      "  [Train] Main Acc: 96.41%\n",
      "    - Aux Acc (aux_0): 98.43%\n",
      "    - Aux Acc (aux_1): 96.30%\n",
      "    - Aux Acc (aux_4): 97.35%\n",
      "    - Aux Acc (aux_5): 99.41%\n",
      "    - Aux Acc (aux_6): 97.98%\n",
      "    - Aux Acc (aux_7): 95.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Validation: 100%|██████████| 72/72 [00:17<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 91.12%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 91.12%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Training: 100%|██████████| 1712/1712 [23:05<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50:\n",
      "  [Train] Total Loss: nan (Main: 0.1002 + Aux: nan)\n",
      "  [Train] Main Acc: 96.72%\n",
      "    - Aux Acc (aux_0): 98.76%\n",
      "    - Aux Acc (aux_1): 96.65%\n",
      "    - Aux Acc (aux_4): 97.57%\n",
      "    - Aux Acc (aux_5): 99.48%\n",
      "    - Aux Acc (aux_6): 98.12%\n",
      "    - Aux Acc (aux_7): 95.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Validation: 100%|██████████| 72/72 [00:56<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 92.00%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 92.00%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Training: 100%|██████████| 1712/1712 [22:38<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0942 + Aux: nan)\n",
      "  [Train] Main Acc: 96.96%\n",
      "    - Aux Acc (aux_0): 98.67%\n",
      "    - Aux Acc (aux_1): 96.86%\n",
      "    - Aux Acc (aux_4): 97.83%\n",
      "    - Aux Acc (aux_5): 99.50%\n",
      "    - Aux Acc (aux_6): 98.21%\n",
      "    - Aux Acc (aux_7): 96.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Validation: 100%|██████████| 72/72 [01:53<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 90.06%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Training: 100%|██████████| 1712/1712 [27:57<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0854 + Aux: nan)\n",
      "  [Train] Main Acc: 97.22%\n",
      "    - Aux Acc (aux_0): 98.79%\n",
      "    - Aux Acc (aux_1): 97.27%\n",
      "    - Aux Acc (aux_4): 97.70%\n",
      "    - Aux Acc (aux_5): 99.55%\n",
      "    - Aux Acc (aux_6): 98.40%\n",
      "    - Aux Acc (aux_7): 96.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Validation: 100%|██████████| 72/72 [00:45<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 91.56%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Training: 100%|██████████| 1712/1712 [48:56<00:00,  1.72s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0790 + Aux: nan)\n",
      "  [Train] Main Acc: 97.46%\n",
      "    - Aux Acc (aux_0): 98.84%\n",
      "    - Aux Acc (aux_1): 97.41%\n",
      "    - Aux Acc (aux_4): 97.88%\n",
      "    - Aux Acc (aux_5): 99.62%\n",
      "    - Aux Acc (aux_6): 98.37%\n",
      "    - Aux Acc (aux_7): 96.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Validation: 100%|██████████| 72/72 [00:42<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.14%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 93.14%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Training: 100%|██████████| 1712/1712 [46:26<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0735 + Aux: nan)\n",
      "  [Train] Main Acc: 97.58%\n",
      "    - Aux Acc (aux_0): 98.86%\n",
      "    - Aux Acc (aux_1): 97.51%\n",
      "    - Aux Acc (aux_4): 98.06%\n",
      "    - Aux Acc (aux_5): 99.62%\n",
      "    - Aux Acc (aux_6): 98.56%\n",
      "    - Aux Acc (aux_7): 96.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Validation: 100%|██████████| 72/72 [00:38<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 90.85%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Training: 100%|██████████| 1712/1712 [43:39<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0671 + Aux: nan)\n",
      "  [Train] Main Acc: 97.81%\n",
      "    - Aux Acc (aux_0): 99.08%\n",
      "    - Aux Acc (aux_1): 97.66%\n",
      "    - Aux Acc (aux_4): 98.07%\n",
      "    - Aux Acc (aux_5): 99.55%\n",
      "    - Aux Acc (aux_6): 98.61%\n",
      "    - Aux Acc (aux_7): 97.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Validation: 100%|██████████| 72/72 [00:42<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 91.56%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Training: 100%|██████████| 1712/1712 [42:34<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0692 + Aux: nan)\n",
      "  [Train] Main Acc: 97.74%\n",
      "    - Aux Acc (aux_0): 99.08%\n",
      "    - Aux Acc (aux_1): 97.54%\n",
      "    - Aux Acc (aux_4): 98.24%\n",
      "    - Aux Acc (aux_5): 99.60%\n",
      "    - Aux Acc (aux_6): 98.71%\n",
      "    - Aux Acc (aux_7): 97.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Validation: 100%|██████████| 72/72 [01:22<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.49%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 93.49%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Training: 100%|██████████| 1712/1712 [46:11<00:00,  1.62s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0592 + Aux: nan)\n",
      "  [Train] Main Acc: 98.02%\n",
      "    - Aux Acc (aux_0): 99.08%\n",
      "    - Aux Acc (aux_1): 97.71%\n",
      "    - Aux Acc (aux_4): 98.23%\n",
      "    - Aux Acc (aux_5): 99.62%\n",
      "    - Aux Acc (aux_6): 98.86%\n",
      "    - Aux Acc (aux_7): 97.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Validation: 100%|██████████| 72/72 [01:03<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 92.52%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Training: 100%|██████████| 1712/1712 [42:12<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0586 + Aux: nan)\n",
      "  [Train] Main Acc: 98.05%\n",
      "    - Aux Acc (aux_0): 99.22%\n",
      "    - Aux Acc (aux_1): 98.04%\n",
      "    - Aux Acc (aux_4): 98.24%\n",
      "    - Aux Acc (aux_5): 99.62%\n",
      "    - Aux Acc (aux_6): 98.75%\n",
      "    - Aux Acc (aux_7): 97.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Validation: 100%|██████████| 72/72 [00:59<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 92.17%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Training: 100%|██████████| 1712/1712 [39:29<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0564 + Aux: nan)\n",
      "  [Train] Main Acc: 98.14%\n",
      "    - Aux Acc (aux_0): 99.22%\n",
      "    - Aux Acc (aux_1): 97.86%\n",
      "    - Aux Acc (aux_4): 98.31%\n",
      "    - Aux Acc (aux_5): 99.65%\n",
      "    - Aux Acc (aux_6): 98.84%\n",
      "    - Aux Acc (aux_7): 97.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Validation: 100%|██████████| 72/72 [01:22<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.67%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 93.67%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Training: 100%|██████████| 1712/1712 [42:13<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0517 + Aux: nan)\n",
      "  [Train] Main Acc: 98.29%\n",
      "    - Aux Acc (aux_0): 99.19%\n",
      "    - Aux Acc (aux_1): 98.03%\n",
      "    - Aux Acc (aux_4): 98.39%\n",
      "    - Aux Acc (aux_5): 99.68%\n",
      "    - Aux Acc (aux_6): 98.92%\n",
      "    - Aux Acc (aux_7): 98.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Validation: 100%|██████████| 72/72 [01:10<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 92.70%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Training: 100%|██████████| 1712/1712 [37:26<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0523 + Aux: nan)\n",
      "  [Train] Main Acc: 98.25%\n",
      "    - Aux Acc (aux_0): 99.27%\n",
      "    - Aux Acc (aux_1): 97.98%\n",
      "    - Aux Acc (aux_4): 98.49%\n",
      "    - Aux Acc (aux_5): 99.65%\n",
      "    - Aux Acc (aux_6): 98.89%\n",
      "    - Aux Acc (aux_7): 97.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Validation: 100%|██████████| 72/72 [01:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.32%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Training: 100%|██████████| 1712/1712 [32:42<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0471 + Aux: nan)\n",
      "  [Train] Main Acc: 98.46%\n",
      "    - Aux Acc (aux_0): 99.35%\n",
      "    - Aux Acc (aux_1): 98.31%\n",
      "    - Aux Acc (aux_4): 98.48%\n",
      "    - Aux Acc (aux_5): 99.74%\n",
      "    - Aux Acc (aux_6): 98.94%\n",
      "    - Aux Acc (aux_7): 97.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Validation: 100%|██████████| 72/72 [00:26<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 94.37%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 94.37%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Training: 100%|██████████| 1712/1712 [30:32<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0529 + Aux: nan)\n",
      "  [Train] Main Acc: 98.23%\n",
      "    - Aux Acc (aux_0): 99.35%\n",
      "    - Aux Acc (aux_1): 98.09%\n",
      "    - Aux Acc (aux_4): 98.42%\n",
      "    - Aux Acc (aux_5): 99.66%\n",
      "    - Aux Acc (aux_6): 98.99%\n",
      "    - Aux Acc (aux_7): 98.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Validation: 100%|██████████| 72/72 [00:29<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.14%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Training: 100%|██████████| 1712/1712 [29:33<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0437 + Aux: nan)\n",
      "  [Train] Main Acc: 98.58%\n",
      "    - Aux Acc (aux_0): 99.39%\n",
      "    - Aux Acc (aux_1): 98.34%\n",
      "    - Aux Acc (aux_4): 98.57%\n",
      "    - Aux Acc (aux_5): 99.71%\n",
      "    - Aux Acc (aux_6): 99.10%\n",
      "    - Aux Acc (aux_7): 97.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Validation: 100%|██████████| 72/72 [00:57<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.14%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Training: 100%|██████████| 1712/1712 [28:53<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0452 + Aux: nan)\n",
      "  [Train] Main Acc: 98.45%\n",
      "    - Aux Acc (aux_0): 99.38%\n",
      "    - Aux Acc (aux_1): 98.37%\n",
      "    - Aux Acc (aux_4): 98.55%\n",
      "    - Aux Acc (aux_5): 99.70%\n",
      "    - Aux Acc (aux_6): 98.94%\n",
      "    - Aux Acc (aux_7): 98.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Validation: 100%|██████████| 72/72 [00:25<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 92.52%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Training: 100%|██████████| 1712/1712 [29:13<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0454 + Aux: nan)\n",
      "  [Train] Main Acc: 98.59%\n",
      "    - Aux Acc (aux_0): 99.36%\n",
      "    - Aux Acc (aux_1): 98.27%\n",
      "    - Aux Acc (aux_4): 98.62%\n",
      "    - Aux Acc (aux_5): 99.69%\n",
      "    - Aux Acc (aux_6): 99.13%\n",
      "    - Aux Acc (aux_7): 97.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Validation: 100%|██████████| 72/72 [00:25<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 92.96%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Training: 100%|██████████| 1712/1712 [29:17<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0447 + Aux: nan)\n",
      "  [Train] Main Acc: 98.51%\n",
      "    - Aux Acc (aux_0): 99.38%\n",
      "    - Aux Acc (aux_1): 98.51%\n",
      "    - Aux Acc (aux_4): 98.59%\n",
      "    - Aux Acc (aux_5): 99.68%\n",
      "    - Aux Acc (aux_6): 99.15%\n",
      "    - Aux Acc (aux_7): 98.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Validation: 100%|██████████| 72/72 [00:24<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 94.11%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Training: 100%|██████████| 1712/1712 [31:40<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0432 + Aux: nan)\n",
      "  [Train] Main Acc: 98.63%\n",
      "    - Aux Acc (aux_0): 99.40%\n",
      "    - Aux Acc (aux_1): 98.41%\n",
      "    - Aux Acc (aux_4): 98.73%\n",
      "    - Aux Acc (aux_5): 99.76%\n",
      "    - Aux Acc (aux_6): 99.06%\n",
      "    - Aux Acc (aux_7): 98.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Validation: 100%|██████████| 72/72 [00:39<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 94.02%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Training: 100%|██████████| 1712/1712 [29:48<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0428 + Aux: nan)\n",
      "  [Train] Main Acc: 98.54%\n",
      "    - Aux Acc (aux_0): 99.35%\n",
      "    - Aux Acc (aux_1): 98.51%\n",
      "    - Aux Acc (aux_4): 98.58%\n",
      "    - Aux Acc (aux_5): 99.72%\n",
      "    - Aux Acc (aux_6): 99.16%\n",
      "    - Aux Acc (aux_7): 98.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Validation: 100%|██████████| 72/72 [00:55<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 92.08%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Training: 100%|██████████| 1712/1712 [29:15<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0377 + Aux: nan)\n",
      "  [Train] Main Acc: 98.71%\n",
      "    - Aux Acc (aux_0): 99.38%\n",
      "    - Aux Acc (aux_1): 98.48%\n",
      "    - Aux Acc (aux_4): 98.82%\n",
      "    - Aux Acc (aux_5): 99.68%\n",
      "    - Aux Acc (aux_6): 99.12%\n",
      "    - Aux Acc (aux_7): 98.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Validation: 100%|██████████| 72/72 [00:24<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.32%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Training: 100%|██████████| 1712/1712 [34:38<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0392 + Aux: nan)\n",
      "  [Train] Main Acc: 98.73%\n",
      "    - Aux Acc (aux_0): 99.49%\n",
      "    - Aux Acc (aux_1): 98.56%\n",
      "    - Aux Acc (aux_4): 98.48%\n",
      "    - Aux Acc (aux_5): 99.74%\n",
      "    - Aux Acc (aux_6): 99.23%\n",
      "    - Aux Acc (aux_7): 98.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Validation: 100%|██████████| 72/72 [00:50<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 94.11%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31] Training: 100%|██████████| 1712/1712 [44:38<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0396 + Aux: nan)\n",
      "  [Train] Main Acc: 98.69%\n",
      "    - Aux Acc (aux_0): 99.49%\n",
      "    - Aux Acc (aux_1): 98.58%\n",
      "    - Aux Acc (aux_4): 98.78%\n",
      "    - Aux Acc (aux_5): 99.70%\n",
      "    - Aux Acc (aux_6): 99.28%\n",
      "    - Aux Acc (aux_7): 98.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31] Validation: 100%|██████████| 72/72 [00:46<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.40%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Training: 100%|██████████| 1712/1712 [29:23<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0384 + Aux: nan)\n",
      "  [Train] Main Acc: 98.73%\n",
      "    - Aux Acc (aux_0): 99.35%\n",
      "    - Aux Acc (aux_1): 98.74%\n",
      "    - Aux Acc (aux_4): 98.76%\n",
      "    - Aux Acc (aux_5): 99.79%\n",
      "    - Aux Acc (aux_6): 99.18%\n",
      "    - Aux Acc (aux_7): 98.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Validation: 100%|██████████| 72/72 [00:25<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 94.99%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 94.99%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33] Training: 100%|██████████| 1712/1712 [23:24<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0370 + Aux: nan)\n",
      "  [Train] Main Acc: 98.75%\n",
      "    - Aux Acc (aux_0): 99.40%\n",
      "    - Aux Acc (aux_1): 98.66%\n",
      "    - Aux Acc (aux_4): 98.96%\n",
      "    - Aux Acc (aux_5): 99.72%\n",
      "    - Aux Acc (aux_6): 99.42%\n",
      "    - Aux Acc (aux_7): 98.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33] Validation: 100%|██████████| 72/72 [00:29<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 95.34%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 95.34%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34] Training: 100%|██████████| 1712/1712 [21:05<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0359 + Aux: nan)\n",
      "  [Train] Main Acc: 98.84%\n",
      "    - Aux Acc (aux_0): 99.51%\n",
      "    - Aux Acc (aux_1): 98.59%\n",
      "    - Aux Acc (aux_4): 98.96%\n",
      "    - Aux Acc (aux_5): 99.76%\n",
      "    - Aux Acc (aux_6): 99.32%\n",
      "    - Aux Acc (aux_7): 98.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34] Validation: 100%|██████████| 72/72 [00:18<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.76%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35] Training: 100%|██████████| 1712/1712 [21:24<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0346 + Aux: nan)\n",
      "  [Train] Main Acc: 98.88%\n",
      "    - Aux Acc (aux_0): 99.59%\n",
      "    - Aux Acc (aux_1): 98.85%\n",
      "    - Aux Acc (aux_4): 98.79%\n",
      "    - Aux Acc (aux_5): 99.75%\n",
      "    - Aux Acc (aux_6): 99.19%\n",
      "    - Aux Acc (aux_7): 98.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35] Validation: 100%|██████████| 72/72 [00:17<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 92.35%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36] Training: 100%|██████████| 1712/1712 [20:38<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0355 + Aux: nan)\n",
      "  [Train] Main Acc: 98.90%\n",
      "    - Aux Acc (aux_0): 99.47%\n",
      "    - Aux Acc (aux_1): 98.77%\n",
      "    - Aux Acc (aux_4): 98.85%\n",
      "    - Aux Acc (aux_5): 99.77%\n",
      "    - Aux Acc (aux_6): 99.36%\n",
      "    - Aux Acc (aux_7): 98.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36] Validation: 100%|██████████| 72/72 [00:15<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.67%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37] Training: 100%|██████████| 1712/1712 [21:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0333 + Aux: nan)\n",
      "  [Train] Main Acc: 98.92%\n",
      "    - Aux Acc (aux_0): 99.53%\n",
      "    - Aux Acc (aux_1): 98.75%\n",
      "    - Aux Acc (aux_4): 98.89%\n",
      "    - Aux Acc (aux_5): 99.76%\n",
      "    - Aux Acc (aux_6): 99.24%\n",
      "    - Aux Acc (aux_7): 98.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37] Validation: 100%|██████████| 72/72 [00:15<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.76%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38] Training: 100%|██████████| 1712/1712 [20:28<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0347 + Aux: nan)\n",
      "  [Train] Main Acc: 98.86%\n",
      "    - Aux Acc (aux_0): 99.53%\n",
      "    - Aux Acc (aux_1): 98.77%\n",
      "    - Aux Acc (aux_4): 98.89%\n",
      "    - Aux Acc (aux_5): 99.81%\n",
      "    - Aux Acc (aux_6): 99.36%\n",
      "    - Aux Acc (aux_7): 98.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38] Validation: 100%|██████████| 72/72 [00:16<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.93%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39] Training: 100%|██████████| 1712/1712 [20:53<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0338 + Aux: nan)\n",
      "  [Train] Main Acc: 98.95%\n",
      "    - Aux Acc (aux_0): 99.54%\n",
      "    - Aux Acc (aux_1): 98.85%\n",
      "    - Aux Acc (aux_4): 98.80%\n",
      "    - Aux Acc (aux_5): 99.73%\n",
      "    - Aux Acc (aux_6): 99.26%\n",
      "    - Aux Acc (aux_7): 98.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39] Validation: 100%|██████████| 72/72 [00:15<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.84%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40] Training: 100%|██████████| 1712/1712 [20:24<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0324 + Aux: nan)\n",
      "  [Train] Main Acc: 98.96%\n",
      "    - Aux Acc (aux_0): 99.64%\n",
      "    - Aux Acc (aux_1): 98.82%\n",
      "    - Aux Acc (aux_4): 99.02%\n",
      "    - Aux Acc (aux_5): 99.76%\n",
      "    - Aux Acc (aux_6): 99.35%\n",
      "    - Aux Acc (aux_7): 98.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40] Validation: 100%|██████████| 72/72 [00:16<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.58%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41] Training: 100%|██████████| 1712/1712 [20:22<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0316 + Aux: nan)\n",
      "  [Train] Main Acc: 98.98%\n",
      "    - Aux Acc (aux_0): 99.46%\n",
      "    - Aux Acc (aux_1): 98.84%\n",
      "    - Aux Acc (aux_4): 98.90%\n",
      "    - Aux Acc (aux_5): 99.73%\n",
      "    - Aux Acc (aux_6): 99.35%\n",
      "    - Aux Acc (aux_7): 98.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41] Validation: 100%|██████████| 72/72 [00:15<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 95.43%\n",
      "\n",
      "  ⭐ 최고 성능 모델 저장됨 (Val Acc: 95.43%) ⭐\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42] Training: 100%|██████████| 1712/1712 [20:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0302 + Aux: nan)\n",
      "  [Train] Main Acc: 98.99%\n",
      "    - Aux Acc (aux_0): 99.54%\n",
      "    - Aux Acc (aux_1): 99.01%\n",
      "    - Aux Acc (aux_4): 98.93%\n",
      "    - Aux Acc (aux_5): 99.77%\n",
      "    - Aux Acc (aux_6): 99.38%\n",
      "    - Aux Acc (aux_7): 98.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42] Validation: 100%|██████████| 72/72 [00:16<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.14%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43] Training: 100%|██████████| 1712/1712 [21:13<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0325 + Aux: nan)\n",
      "  [Train] Main Acc: 98.91%\n",
      "    - Aux Acc (aux_0): 99.50%\n",
      "    - Aux Acc (aux_1): 98.86%\n",
      "    - Aux Acc (aux_4): 98.93%\n",
      "    - Aux Acc (aux_5): 99.80%\n",
      "    - Aux Acc (aux_6): 99.40%\n",
      "    - Aux Acc (aux_7): 98.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43] Validation: 100%|██████████| 72/72 [00:16<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 94.11%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44] Training: 100%|██████████| 1712/1712 [20:41<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0324 + Aux: nan)\n",
      "  [Train] Main Acc: 99.00%\n",
      "    - Aux Acc (aux_0): 99.52%\n",
      "    - Aux Acc (aux_1): 98.91%\n",
      "    - Aux Acc (aux_4): 98.97%\n",
      "    - Aux Acc (aux_5): 99.79%\n",
      "    - Aux Acc (aux_6): 99.44%\n",
      "    - Aux Acc (aux_7): 98.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44] Validation: 100%|██████████| 72/72 [00:16<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 94.46%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45] Training: 100%|██████████| 1712/1712 [21:28<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0298 + Aux: nan)\n",
      "  [Train] Main Acc: 99.00%\n",
      "    - Aux Acc (aux_0): 99.57%\n",
      "    - Aux Acc (aux_1): 99.01%\n",
      "    - Aux Acc (aux_4): 99.07%\n",
      "    - Aux Acc (aux_5): 99.76%\n",
      "    - Aux Acc (aux_6): 99.45%\n",
      "    - Aux Acc (aux_7): 98.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45] Validation: 100%|██████████| 72/72 [00:15<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 94.99%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46] Training: 100%|██████████| 1712/1712 [20:27<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0307 + Aux: nan)\n",
      "  [Train] Main Acc: 98.97%\n",
      "    - Aux Acc (aux_0): 99.51%\n",
      "    - Aux Acc (aux_1): 98.90%\n",
      "    - Aux Acc (aux_4): 99.04%\n",
      "    - Aux Acc (aux_5): 99.80%\n",
      "    - Aux Acc (aux_6): 99.36%\n",
      "    - Aux Acc (aux_7): 98.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46] Validation: 100%|██████████| 72/72 [00:15<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.67%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47] Training: 100%|██████████| 1712/1712 [20:09<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0295 + Aux: nan)\n",
      "  [Train] Main Acc: 99.04%\n",
      "    - Aux Acc (aux_0): 99.51%\n",
      "    - Aux Acc (aux_1): 99.01%\n",
      "    - Aux Acc (aux_4): 98.96%\n",
      "    - Aux Acc (aux_5): 99.79%\n",
      "    - Aux Acc (aux_6): 99.40%\n",
      "    - Aux Acc (aux_7): 98.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47] Validation: 100%|██████████| 72/72 [00:13<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.76%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48] Training: 100%|██████████| 1712/1712 [17:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0281 + Aux: nan)\n",
      "  [Train] Main Acc: 99.03%\n",
      "    - Aux Acc (aux_0): 99.60%\n",
      "    - Aux Acc (aux_1): 98.98%\n",
      "    - Aux Acc (aux_4): 98.99%\n",
      "    - Aux Acc (aux_5): 99.80%\n",
      "    - Aux Acc (aux_6): 99.46%\n",
      "    - Aux Acc (aux_7): 99.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48] Validation: 100%|██████████| 72/72 [00:13<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.23%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49] Training: 100%|██████████| 1712/1712 [17:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0310 + Aux: nan)\n",
      "  [Train] Main Acc: 99.06%\n",
      "    - Aux Acc (aux_0): 99.59%\n",
      "    - Aux Acc (aux_1): 99.00%\n",
      "    - Aux Acc (aux_4): 99.04%\n",
      "    - Aux Acc (aux_5): 99.81%\n",
      "    - Aux Acc (aux_6): 99.40%\n",
      "    - Aux Acc (aux_7): 98.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49] Validation: 100%|██████████| 72/72 [00:13<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 93.76%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50] Training: 100%|██████████| 1712/1712 [17:12<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50:\n",
      "  [Train] Total Loss: nan (Main: 0.0274 + Aux: nan)\n",
      "  [Train] Main Acc: 99.09%\n",
      "    - Aux Acc (aux_0): 99.55%\n",
      "    - Aux Acc (aux_1): 98.98%\n",
      "    - Aux Acc (aux_4): 99.07%\n",
      "    - Aux Acc (aux_5): 99.81%\n",
      "    - Aux Acc (aux_6): 99.57%\n",
      "    - Aux Acc (aux_7): 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50] Validation: 100%|██████████| 72/72 [00:13<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Val] Main Acc: 92.88%\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 (저장 경로도 버전별 자동 설정)\n",
    "print(\"모델 학습 시작\")\n",
    "trained_model, best_acc = train_model(model, train_loader, val_loader, device,num_epochs=50, lr=1e-4, version=VERSION )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df66d3d-a980-47dc-8fd6-3af21f8b3585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "학습 완료. 최고 검증 정확도: 95.43%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n학습 완료. 최고 검증 정확도: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f25a60a-eba0-4e39-8bf8-cadf5d9fe31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고 검증 정확도: 95.43%\n",
      "\n",
      "찾은 모델 파일: ['./models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc5_87.60.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc4_86.10.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc21_94.37.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc3_85.84.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc15_93.49.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc41_95.43.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc9_92.00.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc1_68.25.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc8_91.12.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc7_88.83.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc32_94.99.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc2_79.24.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc33_95.34.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc12_93.14.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc6_88.30.pth', './models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc18_93.67.pth']\n",
      "최종 평가에 사용할 모델: ./models/9_1_mobilevit_xs_weight/best_mtl_classifier_epoc9_92.00.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2267610/2797692047.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(latest_model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Specialist Experts] 생성 중 (x11, 입력: 3채널)...\n",
      "    특징 차원 조정: 576 → 384\n",
      "  [Auxiliary Heads] 생성 중 (x6, 개별 expert)...\n",
      "    - aux_0 (패드 0번 담당) 생성 완료 (출력: 7개)\n",
      "    - aux_1 (패드 1번 담당) 생성 완료 (출력: 4개)\n",
      "    - aux_4 (패드 4번 담당) 생성 완료 (출력: 6개)\n",
      "    - aux_5 (패드 5번 담당) 생성 완료 (출력: 3개)\n",
      "    - aux_6 (패드 6번 담당) 생성 완료 (출력: 10개)\n",
      "    - aux_7 (패드 7번 담당) 생성 완료 (출력: 7개)\n",
      "\n",
      "--- 최종 테스트 세트 평가 시작 ---\n",
      "모델 성능 평가 중 (7개 경로 동시 평가)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "평가 진행: 100%|██████████| 72/72 [00:14<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [최종 테스트 결과] ---\n",
      "  ⭐ [Main] 최종 테스트 정확도: 92.28%\n",
      "    - [Aux aux_0] 전문가 정확도: 96.93%\n",
      "    - [Aux aux_1] 전문가 정확도: 90.44%\n",
      "    - [Aux aux_4] 전문가 정확도: 96.23%\n",
      "    - [Aux aux_5] 전문가 정확도: 99.04%\n",
      "    - [Aux aux_6] 전문가 정확도: 94.56%\n",
      "    - [Aux aux_7] 전문가 정확도: 94.21%\n",
      "\n",
      "[논문용] 7개 혼동 행렬(Confusion Matrix) 생성 중...\n",
      "  - (1/7) Main CM 저장 완료.\n",
      "  - (2/7) Aux CM (aux_0) 저장 완료.\n",
      "  - (3/7) Aux CM (aux_1) 저장 완료.\n",
      "  - (4/7) Aux CM (aux_4) 저장 완료.\n",
      "  - (5/7) Aux CM (aux_5) 저장 완료.\n",
      "  - (6/7) Aux CM (aux_6) 저장 완료.\n",
      "  - (7/7) Aux CM (aux_7) 저장 완료.\n",
      "모든 평가 및 시각화 완료.\n",
      "\n",
      "최종 [Main] 테스트 정확도: 92.28%\n",
      "평가 결과가 ./results/9_1_mobilevit_xs_result/ 폴더에 7개의 CM 이미지와 .pkl 파일로 저장되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2640x2640 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# [수정된 셀 16] 최고 성능 모델 로드 및 최종 평가\n",
    "# - 수정된 evaluate_model 함수 호출\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"최고 검증 정확도: {best_acc:.2f}%\\n\")\n",
    "\n",
    "# 최고 성능 모델 파일 찾기\n",
    "model_files = glob.glob(f'./models/{VERSION}_weight/best_mtl_classifier_epoc*.pth')\n",
    "print(f\"찾은 모델 파일: {model_files}\")\n",
    "\n",
    "if model_files:\n",
    "    # 가장 최근 파일 (또는 최고 성능 파일) 선택\n",
    "    latest_model_path = sorted(model_files)[-1] # (간단히 이름순으로 마지막 파일 선택)\n",
    "    print(f\"최종 평가에 사용할 모델: {latest_model_path}\")\n",
    "    \n",
    "    checkpoint = torch.load(latest_model_path)\n",
    "    \n",
    "    # 라벨 규칙 확인\n",
    "    try:\n",
    "        num_classes = len(MAIN_CLASSES)\n",
    "        aux_groups = AUX_CLASSES_GROUPS\n",
    "    except NameError:\n",
    "        print(\"치명적 오류: [신규 셀]의 라벨 규칙이 필요합니다.\")\n",
    "        raise\n",
    "        \n",
    "    # 평가용 모델 재생성\n",
    "    model_for_test = SensorSetClassifier(\n",
    "        model_name=MODEL_NAME,\n",
    "        feature_dim=FEATURE_DIM,\n",
    "        num_classes_main=num_classes,\n",
    "        aux_classes_groups=aux_groups,\n",
    "        pretrained=False # 가중치를 로드할 것이므로\n",
    "    )\n",
    "    \n",
    "    # 저장된 가중치 로드\n",
    "    model_for_test.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model_for_test = model_for_test.to(device)\n",
    "    \n",
    "    # 최종 성능 평가 (class_names 인자 제거, version 인자 추가)\n",
    "    print(\"\\n--- 최종 테스트 세트 평가 시작 ---\")\n",
    "    results = evaluate_model(model_for_test, test_loader, device, version=VERSION)\n",
    "        \n",
    "    # 결과 저장 (results 딕셔너리에 7개 CM과 7개 정확도 모두 포함됨)\n",
    "    os.makedirs(f'./results/{VERSION}_result', exist_ok=True)\n",
    "    with open(f'./results/{VERSION}_result/evaluation_results_MTL.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "        \n",
    "    print(f\"\\n최종 [Main] 테스트 정확도: {results['accuracies']['main']:.2f}%\")\n",
    "    print(f\"평가 결과가 ./results/{VERSION}_result/ 폴더에 7개의 CM 이미지와 .pkl 파일로 저장되었습니다.\")\n",
    "\n",
    "else:\n",
    "    print(\"훈련된 모델 파일(.pth)을 찾을 수 없습니다!\")\n",
    "    print(f\"경로 확인: ./models/{VERSION}_weight/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09081de1-071f-45e8-b1a2-ee85f2a198de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 및 평가 완료\n"
     ]
    }
   ],
   "source": [
    "# GPU 메모리 최종 정리\n",
    "clear_gpu_memory()\n",
    "print(\"학습 및 평가 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dipstick_custom_env",
   "language": "python",
   "name": "dipstick_custom_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
